# classifier.py
# Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì™„ì „ ê°œì„ ëœ ë¶„ë¥˜ ì—”ì§„
# Korean/Global ëª¨ë“œ ë¶„ê¸° ì²˜ë¦¬ì™€ ë‹¤êµ­ì–´ í‚¤ì›Œë“œ ë¶„ì„ ì§€ì›

import re
import json
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from collections import defaultdict

class Epic7Classifier:
    """Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¶„ë¥˜ ì—”ì§„"""
    
    def __init__(self, mode: str = "all"):
        """
        ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        Args:
            mode: 'korean', 'global', 'all'
        """
        self.mode = mode
        self.load_keywords()
        self.load_source_config()
        
        print(f"[INFO] Epic7 ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {mode})")
    
    def load_keywords(self):
        """ë‹¤êµ­ì–´ í‚¤ì›Œë“œ ë¡œë“œ"""
        
        # í•œêµ­ì–´ ë²„ê·¸ í‚¤ì›Œë“œ
        self.korean_bug_keywords = [
            'ë²„ê·¸', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë¬¸ì œ', 'ì•ˆë˜', 'ì•ˆë¨', 'ì‘ë™ì•ˆí•¨',
            'ì‹¤í–‰ì•ˆë¨', 'ë©ˆì¶¤', 'ì •ì§€', 'ëŠê¹€', 'íŠ•ê¹€', 'í¬ë˜ì‹œ',
            'ì´ìƒí•¨', 'ì´ìƒí•´', 'ë¹„ì •ìƒ', 'ì •ìƒì‘ë™ì•ˆí•¨',
            'ë¡œë”©ì•ˆë¨', 'ì ‘ì†ì•ˆë¨', 'ì—°ê²°ì•ˆë¨', 'ì„œë²„ì˜¤ë¥˜',
            'ê²Œì„ì˜¤ë¥˜', 'ì•±ì˜¤ë¥˜', 'í™”ë©´ì˜¤ë¥˜', 'ì‚¬ìš´ë“œì˜¤ë¥˜',
            'ê²°ì œì˜¤ë¥˜', 'ì—…ë°ì´íŠ¸ì˜¤ë¥˜', 'ì„¤ì¹˜ì˜¤ë¥˜'
        ]
        
        # ì˜ì–´ ë²„ê·¸ í‚¤ì›Œë“œ
        self.english_bug_keywords = [
            'bug', 'error', 'issue', 'problem', 'glitch', 'crash',
            'broken', 'not working', 'doesnt work', 'not responding',
            'frozen', 'stuck', 'loading issue', 'connection error',
            'server error', 'payment error', 'update error',
            'installation error', 'game error', 'app error',
            'screen error', 'sound error', 'visual bug',
            'gameplay bug', 'ui bug', 'interface bug'
        ]
        
        # í•œêµ­ì–´ ê¸ì • í‚¤ì›Œë“œ
        self.korean_positive_keywords = [
            'ì¢‹ì•„', 'ì¢‹ë‹¤', 'ìµœê³ ', 'êµ¿', 'êµ¿êµ¿', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ',
            'ìˆ˜ê³ ', 'ì˜í–ˆ', 'ì˜ë§Œë“¤', 'ì™„ë²½', 'í›Œë¥­', 'ë©‹ì§€', 'ì©ë‹¤',
            'ëŒ€ë°•', 'ê°œì¢‹', 'ê°œì©', 'ì‚¬ë‘', 'â¤ï¸', 'â™¥ï¸', 'ğŸ‘',
            'ğŸ‘', 'ğŸ”¥', 'ğŸ’¯', 'ê°œì„ ', 'í–¥ìƒ', 'ì—…ê·¸ë ˆì´ë“œ',
            'íŒ¨ì¹˜êµ¿', 'ì—…ë°ì´íŠ¸êµ¿', 'ë°¸ëŸ°ìŠ¤êµ¿'
        ]
        
        # ì˜ì–´ ê¸ì • í‚¤ì›Œë“œ
        self.english_positive_keywords = [
            'good', 'great', 'awesome', 'amazing', 'excellent',
            'perfect', 'love', 'like', 'enjoy', 'fun', 'cool',
            'nice', 'wonderful', 'fantastic', 'brilliant',
            'improvement', 'better', 'upgrade', 'enhanced',
            'thanks', 'thank you', 'appreciate', 'well done',
            'â¤ï¸', 'â™¥ï¸', 'ğŸ‘', 'ğŸ‘', 'ğŸ”¥', 'ğŸ’¯'
        ]
        
        # í•œêµ­ì–´ ë¶€ì • í‚¤ì›Œë“œ
        self.korean_negative_keywords = [
            'ì‹«ì–´', 'ì‹«ë‹¤', 'ë³„ë¡œ', 'ì•ˆì¢‹', 'ë‚˜ì˜', 'ìµœì•…', 'ë§í–ˆ',
            'ì‹¤ë§', 'ì§œì¦', 'í™”ë‚¨', 'ì—´ë°›', 'ë¹¡ì¹¨', 'ê°œë¹¡', 'ê°œì§œì¦',
            'ì“°ë ˆê¸°', 'í—›ì†Œë¦¬', 'ê°œì†Œë¦¬', 'ë­ì§€', 'ì´ìƒí•´', 'ì´ìƒí•¨',
            'ë„ˆë¬´ì–´ë ¤ì›Œ', 'ë„ˆë¬´í˜ë“¤ì–´', 'í¬ê¸°', 'ê·¸ë§Œ', 'íƒˆì£¼',
            'ë°¸ëŸ°ìŠ¤ê°œíŒ', 'ë°¸ëŸ°ìŠ¤ë§', 'ìš´ì˜ì§„', 'ë©ì²­', 'ë°”ë³´'
        ]
        
        # ì˜ì–´ ë¶€ì • í‚¤ì›Œë“œ
        self.english_negative_keywords = [
            'bad', 'terrible', 'awful', 'horrible', 'hate',
            'dislike', 'annoying', 'frustrating', 'disappointed',
            'angry', 'mad', 'stupid', 'dumb', 'trash', 'garbage',
            'worst', 'sucks', 'boring', 'too hard', 'too difficult',
            'give up', 'quit', 'uninstall', 'balance sucks',
            'devs suck', 'developers suck', 'wtf', 'wth'
        ]
        
        # ë²„ê·¸ ì œì™¸ í‚¤ì›Œë“œ (ê¸ì •ì  ë§¥ë½)
        self.bug_exclusion_keywords = [
            'ìˆ˜ì •', 'í•´ê²°', 'ê³ ì¹¨', 'íŒ¨ì¹˜', 'ì—…ë°ì´íŠ¸', 'ê°œì„ ',
            'fixed', 'solved', 'patched', 'updated', 'improved',
            'ë²„ê·¸ìˆ˜ì •', 'ì˜¤ë¥˜ìˆ˜ì •', 'bug fix', 'error fix',
            'ë¬¸ì œí•´ê²°', 'issue resolved'
        ]
        
        # ê³ ìš°ì„ ìˆœìœ„ ë²„ê·¸ í‚¤ì›Œë“œ (ì¶”ê°€ë¨)
        self.high_priority_bug_keywords = [
            'í¬ë˜ì‹œ', 'ê°•ì œì¢…ë£Œ', 'ë©ˆì¶¤', 'ì •ì§€', 'íŠ•ê¹€',
            'crash', 'force close', 'frozen', 'stuck',
            'ì„œë²„ì˜¤ë¥˜', 'ì ‘ì†ì•ˆë¨', 'ë¡œê·¸ì¸ì•ˆë¨',
            'server error', 'connection error', 'login error',
            'ê²°ì œì˜¤ë¥˜', 'ì—…ë°ì´íŠ¸ì˜¤ë¥˜', 'ì„¤ì¹˜ì˜¤ë¥˜',
            'payment error', 'update error', 'installation error',
            'ë°ì´í„°ì†ì‹¤', 'ì§„í–‰ì•ˆë¨', 'ê²Œì„ì•ˆë¨',
            'data loss', 'progress lost', 'game broken'
        ]
    
    def load_source_config(self):
        """ì†ŒìŠ¤ë³„ ì„¤ì • ë¡œë“œ"""
        self.source_config = {
            # í•œêµ­ ì†ŒìŠ¤
            'stove_bug': {
                'type': 'korean',
                'weight': 1.0,
                'bug_priority': 'high',
                'sentiment_weight': 0.8
            },
            'stove_general': {
                'type': 'korean',
                'weight': 0.8,
                'bug_priority': 'medium',
                'sentiment_weight': 1.0
            },
            'ruliweb_epic7': {
                'type': 'korean',
                'weight': 0.9,
                'bug_priority': 'medium',
                'sentiment_weight': 0.9
            },
            
            # ê¸€ë¡œë²Œ ì†ŒìŠ¤
            'stove_global_bug': {
                'type': 'global',
                'weight': 1.0,
                'bug_priority': 'high',
                'sentiment_weight': 0.8
            },
            'stove_global_general': {
                'type': 'global',
                'weight': 0.8,
                'bug_priority': 'medium',
                'sentiment_weight': 1.0
            },
            'reddit_epic7': {
                'type': 'global',
                'weight': 0.9,
                'bug_priority': 'medium',
                'sentiment_weight': 0.9
            },
            'official_forum': {
                'type': 'global',
                'weight': 0.7,
                'bug_priority': 'low',
                'sentiment_weight': 0.7
            }
        }
    
    def is_korean_text(self, text: str) -> bool:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ íŒë³„"""
        if not text:
            return False
        
        korean_count = len(re.findall(r'[ê°€-í£]', text))
        total_chars = len(re.findall(r'[ê°€-í£a-zA-Z]', text))
        
        if total_chars == 0:
            return False
        
        return korean_count / total_chars > 0.3
    
    def is_bug_post(self, title: str, content: str = "", source: str = "") -> Tuple[bool, float, str]:
        """
        ë²„ê·¸ ê²Œì‹œê¸€ íŒë³„ (ë‹¤êµ­ì–´ ì§€ì›)
        
        Returns:
            (is_bug, confidence, reason)
        """
        if not title:
            return False, 0.0, "ì œëª© ì—†ìŒ"
        
        # ì†ŒìŠ¤ê°€ ë²„ê·¸ ì „ìš© ê²Œì‹œíŒì¸ ê²½ìš°
        if source in ['stove_bug', 'stove_global_bug']:
            return True, 1.0, f"ë²„ê·¸ ì „ìš© ê²Œì‹œíŒ ({source})"
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = (title + " " + content).lower().strip()
        
        # ë²„ê·¸ ì œì™¸ í‚¤ì›Œë“œ í™•ì¸ (ê¸ì •ì  ë§¥ë½)
        for exclusion in self.bug_exclusion_keywords:
            if exclusion in text:
                return False, 0.0, f"ë²„ê·¸ ì œì™¸ í‚¤ì›Œë“œ ë°œê²¬: {exclusion}"
        
        # ì–¸ì–´ íŒë³„
        is_korean = self.is_korean_text(text)
        
        # ë²„ê·¸ í‚¤ì›Œë“œ ë§¤ì¹­
        bug_keywords = self.korean_bug_keywords if is_korean else self.english_bug_keywords
        
        matched_keywords = []
        confidence = 0.0
        
        for keyword in bug_keywords:
            if keyword in text:
                matched_keywords.append(keyword)
                
                # í‚¤ì›Œë“œë³„ ê°€ì¤‘ì¹˜ ì ìš©
                if keyword in ['ë²„ê·¸', 'bug', 'ì˜¤ë¥˜', 'error']:
                    confidence += 0.4
                elif keyword in ['ë¬¸ì œ', 'issue', 'problem']:
                    confidence += 0.3
                else:
                    confidence += 0.2
        
        # ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        if source in self.source_config:
            source_weight = self.source_config[source]['weight']
            confidence *= source_weight
        
        # ì„ê³„ê°’ íŒë³„
        is_bug = confidence >= 0.3
        
        reason = f"ë§¤ì¹­ í‚¤ì›Œë“œ: {', '.join(matched_keywords)}" if matched_keywords else "í‚¤ì›Œë“œ ì—†ìŒ"
        
        return is_bug, min(confidence, 1.0), reason
    
    def is_high_priority_bug(self, title: str, content: str = "", source: str = "") -> bool:
        """
        ê³ ìš°ì„ ìˆœìœ„ ë²„ê·¸ íŒë³„ (ìƒˆë¡œ ì¶”ê°€ëœ í•¨ìˆ˜)
        
        Args:
            title: ê²Œì‹œê¸€ ì œëª©
            content: ê²Œì‹œê¸€ ë‚´ìš©
            source: ì†ŒìŠ¤ íƒ€ì…
            
        Returns:
            bool: ê³ ìš°ì„ ìˆœìœ„ ë²„ê·¸ ì—¬ë¶€
        """
        if not title:
            return False
        
        # ë¨¼ì € ë²„ê·¸ ê²Œì‹œê¸€ì¸ì§€ í™•ì¸
        is_bug, confidence, _ = self.is_bug_post(title, content, source)
        
        if not is_bug:
            return False
        
        # ì†ŒìŠ¤ë³„ ìš°ì„ ìˆœìœ„ í™•ì¸
        if source in self.source_config:
            source_priority = self.source_config[source].get('bug_priority', 'medium')
            if source_priority == 'high':
                return True
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = (title + " " + content).lower().strip()
        
        # ê³ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in self.high_priority_bug_keywords:
            if keyword in text:
                return True
        
        # ë²„ê·¸ ì‹ ë¢°ë„ê°€ ë§¤ìš° ë†’ì€ ê²½ìš°
        if confidence >= 0.8:
            return True
        
        return False
    
    def analyze_sentiment(self, title: str, content: str = "", source: str = "") -> Tuple[str, float, str]:
        """
        ê°ì„± ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›)
        
        Returns:
            (sentiment, confidence, reason)
        """
        if not title:
            return "neutral", 0.0, "ì œëª© ì—†ìŒ"
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = (title + " " + content).lower().strip()
        
        # ì–¸ì–´ íŒë³„
        is_korean = self.is_korean_text(text)
        
        # ê°ì„± í‚¤ì›Œë“œ ì„ íƒ
        positive_keywords = self.korean_positive_keywords if is_korean else self.english_positive_keywords
        negative_keywords = self.korean_negative_keywords if is_korean else self.english_negative_keywords
        
        # ê°ì„± ì ìˆ˜ ê³„ì‚°
        positive_score = 0.0
        negative_score = 0.0
        
        positive_matches = []
        negative_matches = []
        
        # ê¸ì • í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in positive_keywords:
            if keyword in text:
                positive_matches.append(keyword)
                positive_score += 0.3
        
        # ë¶€ì • í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in negative_keywords:
            if keyword in text:
                negative_matches.append(keyword)
                negative_score += 0.3
        
        # ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        if source in self.source_config:
            sentiment_weight = self.source_config[source]['sentiment_weight']
            positive_score *= sentiment_weight
            negative_score *= sentiment_weight
        
        # ê°ì„± íŒë³„
        if positive_score > negative_score and positive_score >= 0.3:
            sentiment = "positive"
            confidence = min(positive_score, 1.0)
            reason = f"ê¸ì • í‚¤ì›Œë“œ: {', '.join(positive_matches)}"
        elif negative_score > positive_score and negative_score >= 0.3:
            sentiment = "negative"
            confidence = min(negative_score, 1.0)
            reason = f"ë¶€ì • í‚¤ì›Œë“œ: {', '.join(negative_matches)}"
        else:
            sentiment = "neutral"
            confidence = 0.5
            reason = "ì¤‘ë¦½ì  ë‚´ìš©"
        
        return sentiment, confidence, reason
    
    def classify_post(self, post_data: Dict) -> Dict:
        """
        ê²Œì‹œê¸€ ì¢…í•© ë¶„ë¥˜
        
        Args:
            post_data: {
                'title': str,
                'content': str,
                'source': str,
                'url': str,
                'timestamp': str
            }
        
        Returns:
            ë¶„ë¥˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        title = post_data.get('title', '')
        content = post_data.get('content', '')
        source = post_data.get('source', '')
        
        # ë²„ê·¸ ë¶„ì„
        is_bug, bug_confidence, bug_reason = self.is_bug_post(title, content, source)
        
        # ê°ì„± ë¶„ì„
        sentiment, sentiment_confidence, sentiment_reason = self.analyze_sentiment(title, content, source)
        
        # ì†ŒìŠ¤ íƒ€ì… í™•ì¸
        source_type = 'unknown'
        if source in self.source_config:
            source_type = self.source_config[source]['type']
        
        # ì–¸ì–´ íŒë³„
        language = 'korean' if self.is_korean_text(title + " " + content) else 'english'
        
        # ìµœì¢… ì¹´í…Œê³ ë¦¬ ê²°ì •
        if is_bug:
            category = 'bug'
            priority = self.source_config.get(source, {}).get('bug_priority', 'medium')
        elif sentiment == 'positive':
            category = 'positive'
            priority = 'low'
        elif sentiment == 'negative':
            category = 'negative'
            priority = 'medium'
        else:
            category = 'neutral'
            priority = 'low'
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'category': category,
            'priority': priority,
            'language': language,
            'source_type': source_type,
            'bug_analysis': {
                'is_bug': is_bug,
                'confidence': bug_confidence,
                'reason': bug_reason
            },
            'sentiment_analysis': {
                'sentiment': sentiment,
                'confidence': sentiment_confidence,
                'reason': sentiment_reason
            },
            'classification_timestamp': datetime.now().isoformat(),
            'classifier_version': 'Enhanced Complete v2.0'
        }
        
        return result
    
    def get_category_emoji(self, category: str) -> str:
        """ì¹´í…Œê³ ë¦¬ë³„ ì´ëª¨ì§€ ë°˜í™˜"""
        emoji_map = {
            'bug': 'ğŸ›',
            'positive': 'ğŸ˜Š',
            'negative': 'ğŸ˜',
            'neutral': 'ğŸ˜'
        }
        return emoji_map.get(category, 'â“')
    
    def should_send_alert(self, classification: Dict) -> bool:
        """ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€ íŒë³„"""
        category = classification.get('category', 'neutral')
        priority = classification.get('priority', 'low')
        
        # ë²„ê·¸ëŠ” í•­ìƒ ì•Œë¦¼
        if category == 'bug':
            return True
        
        # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²½ìš° ì•Œë¦¼
        if priority == 'high':
            return True
        
        # ë¶€ì •ì  ê°ì„±ì´ ë†’ì€ ê²½ìš° ì•Œë¦¼
        sentiment_confidence = classification.get('sentiment_analysis', {}).get('confidence', 0.0)
        if category == 'negative' and sentiment_confidence >= 0.7:
            return True
        
        return False
    
    def get_classification_summary(self, classifications: List[Dict]) -> Dict:
        """ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½"""
        if not classifications:
            return {}
        
        total_count = len(classifications)
        category_counts = defaultdict(int)
        language_counts = defaultdict(int)
        source_type_counts = defaultdict(int)
        
        for classification in classifications:
            category_counts[classification.get('category', 'neutral')] += 1
            language_counts[classification.get('language', 'unknown')] += 1
            source_type_counts[classification.get('source_type', 'unknown')] += 1
        
        summary = {
            'total_posts': total_count,
            'category_distribution': dict(category_counts),
            'language_distribution': dict(language_counts),
            'source_type_distribution': dict(source_type_counts),
            'bug_ratio': category_counts['bug'] / total_count if total_count > 0 else 0,
            'positive_ratio': category_counts['positive'] / total_count if total_count > 0 else 0,
            'negative_ratio': category_counts['negative'] / total_count if total_count > 0 else 0,
            'summary_timestamp': datetime.now().isoformat()
        }
        
        return summary


# í¸ì˜ í•¨ìˆ˜ë“¤
def is_bug_post(title: str, content: str = "", source: str = "") -> bool:
    """ë²„ê·¸ ê²Œì‹œê¸€ íŒë³„ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    classifier = Epic7Classifier()
    is_bug, _, _ = classifier.is_bug_post(title, content, source)
    return is_bug

def is_high_priority_bug(title: str, content: str = "", source: str = "") -> bool:
    """ê³ ìš°ì„ ìˆœìœ„ ë²„ê·¸ íŒë³„ (ìƒˆë¡œ ì¶”ê°€ëœ í¸ì˜ í•¨ìˆ˜)"""
    classifier = Epic7Classifier()
    return classifier.is_high_priority_bug(title, content, source)

def is_positive_post(title: str, content: str = "", source: str = "") -> bool:
    """ê¸ì • ê²Œì‹œê¸€ íŒë³„ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    classifier = Epic7Classifier()
    sentiment, _, _ = classifier.analyze_sentiment(title, content, source)
    return sentiment == 'positive'

def is_negative_post(title: str, content: str = "", source: str = "") -> bool:
    """ë¶€ì • ê²Œì‹œê¸€ íŒë³„ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    classifier = Epic7Classifier()
    sentiment, _, _ = classifier.analyze_sentiment(title, content, source)
    return sentiment == 'negative'

def classify_post(title: str, content: str = "", source: str = "") -> str:
    """ê²Œì‹œê¸€ ë¶„ë¥˜ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    classifier = Epic7Classifier()
    post_data = {
        'title': title,
        'content': content,
        'source': source
    }
    result = classifier.classify_post(post_data)
    return result.get('category', 'neutral')

def get_category_emoji(category: str) -> str:
    """ì¹´í…Œê³ ë¦¬ë³„ ì´ëª¨ì§€ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    classifier = Epic7Classifier()
    return classifier.get_category_emoji(category)


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    classifier = Epic7Classifier(mode="all")
    
    # í…ŒìŠ¤íŠ¸ ê²Œì‹œê¸€
    test_posts = [
        {
            'title': 'ê²Œì„ì—ì„œ í¬ë˜ì‹œ ë²„ê·¸ê°€ ë°œìƒí–ˆì–´ìš”',
            'content': 'ë¡œê·¸ì¸í•  ë•Œ ê³„ì† ê°•ì œì¢…ë£Œê°€ ë‚˜ìš”',
            'source': 'stove_bug'
        },
        {
            'title': 'Game has a crash bug',
            'content': 'Force close occurs during login',
            'source': 'stove_global_bug'
        },
        {
            'title': 'ì´ë²ˆ ì—…ë°ì´íŠ¸ ì •ë§ ì¢‹ì•„ìš”',
            'content': 'ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ í›Œë¥­í•©ë‹ˆë‹¤',
            'source': 'stove_general'
        }
    ]
    
    # ë¶„ë¥˜ ì‹¤í–‰
    results = []
    for post in test_posts:
        result = classifier.classify_post(post)
        results.append(result)
        print(f"ì œëª©: {post['title']}")
        print(f"ë¶„ë¥˜: {result['category']} ({classifier.get_category_emoji(result['category'])})")
        print(f"ê³ ìš°ì„ ìˆœìœ„ ë²„ê·¸: {classifier.is_high_priority_bug(post['title'], post['content'], post['source'])}")
        print(f"ì–¸ì–´: {result['language']}")
        print(f"ì†ŒìŠ¤: {result['source_type']}")
        print("---")
    
    # ìš”ì•½ ì •ë³´
    summary = classifier.get_classification_summary(results)
    print("ë¶„ë¥˜ ìš”ì•½:")
    print(f"ì´ ê²Œì‹œê¸€: {summary['total_posts']}")
    print(f"ì¹´í…Œê³ ë¦¬ ë¶„í¬: {summary['category_distribution']}")
    print(f"ì–¸ì–´ ë¶„í¬: {summary['language_distribution']}")