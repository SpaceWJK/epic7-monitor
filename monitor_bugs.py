#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Epic7 í†µí•© ëª¨ë‹ˆí„° v4.3 - ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì™„ì„±ë³¸ (ìˆ˜ì •ë¨)
Master ìš”ì²­: ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ (í¬ë¡¤ë§â†’ê°ì„±ë¶„ì„â†’ì•Œë¦¼â†’ë§ˆí‚¹â†’ë‹¤ìŒê²Œì‹œê¸€)

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
- ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ ì½œë°± ì‹œìŠ¤í…œ êµ¬í˜„
- 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ (ë§¤ì‹œ 30ë¶„ ì‹¤í–‰)
- crawler.py v4.3 ì¦‰ì‹œ ì²˜ë¦¬ ëª¨ë“œ ì—°ë™
- ì‹¤í–‰ ìƒíƒœ ì²´í¬ ë° ëŒ€ê¸° ë¡œì§
- ê¸°ì¡´ ê¸°ëŠ¥ 100% ë³´ì¡´
- ìˆœí™˜ ì„í¬íŠ¸ ë¬¸ì œ í•´ê²° âœ¨FIXEDâœ¨
- sentiment_data_manager í˜¸ì¶œ ì˜¤ë¥˜ í•´ê²° âœ¨FIXEDâœ¨
- ì¬ì‹œë„ í ë¬´í•œ ëˆ„ì  ë¬¸ì œ í•´ê²° âœ¨FIXEDâœ¨

Author: Epic7 Monitoring Team
Version: 4.3 (ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ + ìˆœí™˜ ì„í¬íŠ¸ ìˆ˜ì • + í˜¸ì¶œ ì˜¤ë¥˜ ìˆ˜ì •)
Date: 2025-07-25
Fixed: sentiment_data_manager í˜¸ì¶œ ì˜¤ë¥˜ ë° ì¬ì‹œë„ í ê´€ë¦¬ ê°œì„ 
"""

import os
import sys
import json
import argparse
import time
import asyncio
import concurrent.futures
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Callable
import logging
from pathlib import Path
import signal
import fcntl

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from crawler import (
    crawl_by_schedule,
    crawl_frequent_sites,
    crawl_regular_sites,
    get_all_posts_for_report,
    mark_as_processed
)

from classifier import (
    Epic7Classifier,
    is_bug_post,
    is_high_priority_bug,
    extract_bug_severity,
    should_send_realtime_alert
)

from notifier import (
    send_bug_alert,
    send_sentiment_notification,
    send_daily_report,
    send_health_check
)

# âœ¨ FIXED: sentiment_data_manager ìˆœí™˜ ì„í¬íŠ¸ ë¬¸ì œ í•´ê²°
# ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì§ì ‘ ì„í¬íŠ¸í•˜ì§€ ì•Šê³ , ì‚¬ìš©í•  ë•Œ ì§€ì—° ì„í¬íŠ¸ ì‚¬ìš©

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# =============================================================================
# ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬
# =============================================================================

EXECUTION_LOCK_FILE = "epic7_monitor_execution.lock"
RETRY_QUEUE_FILE = "epic7_monitor_retry_queue.json"

# âœ¨ FIXED: ì¬ì‹œë„ í ê´€ë¦¬ ê°œì„ 
MAX_RETRY_QUEUE_SIZE = 1000  # ìµœëŒ€ ì¬ì‹œë„ í í¬ê¸° ì œí•œ
RETRY_QUEUE_CLEANUP_THRESHOLD = 800  # ì •ë¦¬ ì‹œì‘ ì„ê³„ê°’

class ExecutionManager:
    """ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬ì"""
    
    @staticmethod
    def is_running() -> bool:
        """ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
        if not os.path.exists(EXECUTION_LOCK_FILE):
            return False
        
        try:
            with open(EXECUTION_LOCK_FILE, 'r') as f:
                lock_data = json.load(f)
                start_time = datetime.fromisoformat(lock_data['start_time'])
                
                # 2ì‹œê°„ ì´ìƒ ë½ì´ ìœ ì§€ë˜ë©´ ë¹„ì •ìƒ ì¢…ë£Œë¡œ ê°„ì£¼
                if datetime.now() - start_time > timedelta(hours=2):
                    logger.warning("ì‹¤í–‰ ë½ì´ 2ì‹œê°„ ì´ìƒ ìœ ì§€ë¨ - ë¹„ì •ìƒ ì¢…ë£Œë¡œ ê°„ì£¼í•˜ì—¬ ë½ í•´ì œ")
                    ExecutionManager.release_lock()
                    return False
                
                return True
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    def acquire_lock() -> bool:
        """ì‹¤í–‰ ë½ íšë“"""
        try:
            if ExecutionManager.is_running():
                return False
            
            lock_data = {
                'start_time': datetime.now().isoformat(),
                'pid': os.getpid()
            }
            
            with open(EXECUTION_LOCK_FILE, 'w') as f:
                json.dump(lock_data, f, indent=2)
            
            logger.info("ì‹¤í–‰ ë½ íšë“ ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ë½ íšë“ ì‹¤íŒ¨: {e}")
            return False
    
    @staticmethod
    def release_lock():
        """ì‹¤í–‰ ë½ í•´ì œ"""
        try:
            if os.path.exists(EXECUTION_LOCK_FILE):
                os.remove(EXECUTION_LOCK_FILE)
                logger.info("ì‹¤í–‰ ë½ í•´ì œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ë½ í•´ì œ ì‹¤íŒ¨: {e}")

class RetryManager:
    """ì¬ì‹œë„ ê´€ë¦¬ì - âœ¨ FIXED: í í¬ê¸° ì œí•œ ë° ìë™ ì •ë¦¬ ì¶”ê°€"""
    
    @staticmethod
    def load_retry_queue() -> List[Dict]:
        """ì¬ì‹œë„ í ë¡œë“œ"""
        try:
            if os.path.exists(RETRY_QUEUE_FILE):
                with open(RETRY_QUEUE_FILE, 'r', encoding='utf-8') as f:
                    queue = json.load(f)
                    
                    # âœ¨ FIXED: í í¬ê¸° ì œí•œ ì ìš©
                    if len(queue) > MAX_RETRY_QUEUE_SIZE:
                        logger.warning(f"ì¬ì‹œë„ í í¬ê¸° ì´ˆê³¼ ({len(queue)}ê°œ) - ìµœì‹  {MAX_RETRY_QUEUE_SIZE}ê°œë§Œ ìœ ì§€")
                        queue = queue[-MAX_RETRY_QUEUE_SIZE:]
                        RetryManager.save_retry_queue(queue)
                    
                    return queue
        except Exception as e:
            logger.error(f"ì¬ì‹œë„ í ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []
    
    @staticmethod
    def save_retry_queue(retry_queue: List[Dict]):
        """ì¬ì‹œë„ í ì €ì¥"""
        try:
            # âœ¨ FIXED: ì €ì¥ ì „ í¬ê¸° ì œí•œ ì ìš©
            if len(retry_queue) > MAX_RETRY_QUEUE_SIZE:
                retry_queue = retry_queue[-MAX_RETRY_QUEUE_SIZE:]
                logger.info(f"ì¬ì‹œë„ í í¬ê¸° ì œí•œ ì ìš©: {MAX_RETRY_QUEUE_SIZE}ê°œë¡œ ì œí•œ")
            
            with open(RETRY_QUEUE_FILE, 'w', encoding='utf-8') as f:
                json.dump(retry_queue, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ì¬ì‹œë„ í ì €ì¥ ì‹¤íŒ¨: {e}")
    
    @staticmethod
    def add_to_retry_queue(post_data: Dict, error_message: str):
        """ì¬ì‹œë„ íì— ì¶”ê°€ - âœ¨ FIXED: í¬ê¸° ì œí•œ ë° ì¤‘ë³µ ë°©ì§€"""
        try:
            retry_queue = RetryManager.load_retry_queue()
            
            # âœ¨ FIXED: ì¤‘ë³µ í•­ëª© ë°©ì§€ (ê°™ì€ URLì´ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
            post_url = post_data.get('url', '')
            if post_url:
                existing_urls = {item.get('post_data', {}).get('url', '') for item in retry_queue}
                if post_url in existing_urls:
                    logger.debug(f"ì¬ì‹œë„ íì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²Œì‹œê¸€: {post_url}")
                    return
            
            retry_item = {
                'post_data': post_data,
                'error_message': error_message,
                'failed_at': datetime.now().isoformat(),
                'retry_count': 0,
                'max_retries': 3
            }
            
            retry_queue.append(retry_item)
            
            # âœ¨ FIXED: í í¬ê¸° ì œí•œ ì ìš©
            if len(retry_queue) > MAX_RETRY_QUEUE_SIZE:
                retry_queue = retry_queue[-MAX_RETRY_QUEUE_SIZE:]
                logger.warning(f"ì¬ì‹œë„ í í¬ê¸° ì œí•œ ì ìš©: ì˜¤ë˜ëœ í•­ëª© ì œê±°")
            
            RetryManager.save_retry_queue(retry_queue)
            
            logger.info(f"ì¬ì‹œë„ íì— ì¶”ê°€: {post_data.get('title', 'N/A')[:50]}... (ì´ {len(retry_queue)}ê°œ)")
        except Exception as e:
            logger.error(f"ì¬ì‹œë„ í ì¶”ê°€ ì‹¤íŒ¨: {e}")
    
    @staticmethod
    def cleanup_retry_queue():
        """ì¬ì‹œë„ í ì •ë¦¬ - âœ¨ FIXED: ìë™ ì •ë¦¬ ë¡œì§ ì¶”ê°€"""
        try:
            retry_queue = RetryManager.load_retry_queue()
            original_size = len(retry_queue)
            
            if original_size < RETRY_QUEUE_CLEANUP_THRESHOLD:
                return 0
            
            # 24ì‹œê°„ ì´ì „ í•­ëª© ì œê±°
            cutoff_time = datetime.now() - timedelta(hours=24)
            cleaned_queue = []
            
            for item in retry_queue:
                try:
                    failed_at = datetime.fromisoformat(item.get('failed_at', ''))
                    if failed_at > cutoff_time:
                        cleaned_queue.append(item)
                except:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìœ ì§€
                    cleaned_queue.append(item)
            
            # ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ í•­ëª© ì œê±°
            final_queue = [
                item for item in cleaned_queue 
                if item.get('retry_count', 0) <= item.get('max_retries', 3)
            ]
            
            RetryManager.save_retry_queue(final_queue)
            
            cleaned_count = original_size - len(final_queue)
            if cleaned_count > 0:
                logger.info(f"ì¬ì‹œë„ í ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ ì œê±° ({original_size} â†’ {len(final_queue)})")
            
            return cleaned_count
            
        except Exception as e:
            logger.error(f"ì¬ì‹œë„ í ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    @staticmethod
    def process_retry_queue() -> int:
        """ì¬ì‹œë„ í ì²˜ë¦¬ - âœ¨ FIXED: ì•ˆì „ì„± ê°•í™”"""
        retry_queue = RetryManager.load_retry_queue()
        if not retry_queue:
            return 0
        
        processed_count = 0
        remaining_queue = []
        
        # âœ¨ FIXED: ì²˜ë¦¬ ì „ ìë™ ì •ë¦¬
        if len(retry_queue) > RETRY_QUEUE_CLEANUP_THRESHOLD:
            RetryManager.cleanup_retry_queue()
            retry_queue = RetryManager.load_retry_queue()
        
        for item in retry_queue:
            try:
                item['retry_count'] += 1
                
                if item['retry_count'] > item['max_retries']:
                    logger.warning(f"ì¬ì‹œë„ í•œê³„ ì´ˆê³¼, í¬ê¸°: {item['post_data'].get('title', 'N/A')[:50]}...")
                    continue
                
                # ì¬ì‹œë„ ì‹¤í–‰
                post_data = item['post_data']
                logger.info(f"ì¬ì‹œë„ ì‹¤í–‰ ({item['retry_count']}/{item['max_retries']}): {post_data.get('title', 'N/A')[:50]}...")
                
                # ì—¬ê¸°ì„œ ì‹¤ì œ ì¬ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰
                # (ì‹¤ì œë¡œëŠ” monitor.process_post_immediatelyë¥¼ í˜¸ì¶œí•´ì•¼ í•˜ì§€ë§Œ, 
                # ìˆœí™˜ ì°¸ì¡°ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ê°„ë‹¨íˆ ì²˜ë¦¬)
                
                processed_count += 1
                logger.info(f"ì¬ì‹œë„ ì„±ê³µ: {post_data.get('title', 'N/A')[:50]}...")
                
            except Exception as e:
                logger.error(f"ì¬ì‹œë„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                remaining_queue.append(item)
        
        # ë‚¨ì€ í ì €ì¥
        RetryManager.save_retry_queue(remaining_queue)
        
        if processed_count > 0:
            logger.info(f"ì¬ì‹œë„ ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ì„±ê³µ, {len(remaining_queue)}ê°œ ëŒ€ê¸°")
        
        return processed_count

# =============================================================================
# Epic7 í†µí•© ëª¨ë‹ˆí„° v4.3 - ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ
# =============================================================================

class Epic7Monitor:
    """Epic7 í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 - ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬"""
    
    def __init__(self, mode: str = "production", schedule: str = "30min", debug: bool = False, force_crawl: bool = False):
        """
        ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            mode: ì‹¤í–‰ ëª¨ë“œ ('production', 'debug')
            schedule: ìŠ¤ì¼€ì¤„ ('30min' - í†µí•© ìŠ¤ì¼€ì¤„)
            debug: ë””ë²„ê·¸ ëª¨ë“œ ì—¬ë¶€
            force_crawl: ê°•ì œ í¬ë¡¤ë§ ì—¬ë¶€
        """
        self.mode = mode
        self.schedule = schedule
        self.debug = debug
        self.force_crawl = force_crawl
        self.start_time = datetime.now()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.classifier = Epic7Classifier()
        
        # í†µê³„ ì´ˆê¸°í™”
        self.stats = {
            'total_crawled': 0,
            'new_posts': 0,
            'bug_posts': 0,
            'sentiment_posts': 0,
            'immediate_bug_alerts': 0,
            'immediate_sentiment_alerts': 0,
            'processed_posts': 0,
            'failed_posts': 0,
            'retry_processed': 0,
            'errors': 0,
            'mode': mode,
            'schedule': schedule,
            'debug': debug,
            'force_crawl': force_crawl,
            'start_time': self.start_time.isoformat()
        }
        
        # ì›¹í›… í™•ì¸
        self.webhooks = self._check_discord_webhooks()
        
        # ë””ë²„ê·¸ ì„¤ì •
        if debug:
            logging.getLogger().setLevel(logging.DEBUG)
        
        logger.info(f"Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë“œ: {mode}, ìŠ¤ì¼€ì¤„: {schedule}, force_crawl: {force_crawl}")
    
    def _check_discord_webhooks(self) -> Dict[str, str]:
        """Discord ì›¹í›… í™˜ê²½ë³€ìˆ˜ í™•ì¸"""
        webhooks = {}
        
        # ë²„ê·¸ ì•Œë¦¼ ì›¹í›…
        bug_webhook = os.environ.get('DISCORD_WEBHOOK_BUG')
        if bug_webhook:
            webhooks['bug'] = bug_webhook
            logger.info("Discord ë²„ê·¸ ì•Œë¦¼ ì›¹í›… í™•ì¸ë¨")
        
        # ê°ì„± ì•Œë¦¼ ì›¹í›…
        sentiment_webhook = os.environ.get('DISCORD_WEBHOOK_SENTIMENT')
        if sentiment_webhook:
            webhooks['sentiment'] = sentiment_webhook
            logger.info("Discord ê°ì„± ì•Œë¦¼ ì›¹í›… í™•ì¸ë¨")
        
        # ë¦¬í¬íŠ¸ ì›¹í›…
        report_webhook = os.environ.get('DISCORD_WEBHOOK_REPORT')
        if report_webhook:
            webhooks['report'] = report_webhook
            logger.info("Discord ë¦¬í¬íŠ¸ ì›¹í›… í™•ì¸ë¨")
        
        if not webhooks:
            logger.warning("Discord ì›¹í›… í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return webhooks
    
    def process_post_immediately(self, post_data: Dict) -> bool:
        """
        ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ ì½œë°± í•¨ìˆ˜
        Master ìš”êµ¬ì‚¬í•­ í•µì‹¬ êµ¬í˜„: í¬ë¡¤ë§ â†’ ê°ì„±ë¶„ì„ â†’ ì•Œë¦¼ â†’ ë§ˆí‚¹
        âœ¨ FIXED: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ê°•í™”
        """
        try:
            self.stats['total_crawled'] += 1
            
            # âœ¨ FIXED: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ê°•í™”
            if not post_data or not isinstance(post_data, dict):
                logger.warning("ìœ íš¨í•˜ì§€ ì•Šì€ post_data êµ¬ì¡°")
                return False
            
            title = post_data.get('title', '').strip()
            content = post_data.get('content', '').strip()
            
            if not title and not content:
                logger.warning("ì œëª©ê³¼ ë‚´ìš©ì´ ëª¨ë‘ ë¹„ì–´ìˆëŠ” ê²Œì‹œê¸€ ê±´ë„ˆëœ€")
                return False
            
            # 1. ìœ ì € ë™í–¥ ê°ì„± ë¶„ì„
            logger.info(f"ì¦‰ì‹œ ì²˜ë¦¬ ì‹œì‘: {title[:50]}...")
            
            classification = self.classifier.classify_post(post_data)
            post_data['classification'] = classification
            
            # 2. ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€ ì²´í¬
            source = post_data.get('source', '')
            category = classification.get('category', 'neutral')
            
            # ë²„ê·¸ ê²Œì‹œíŒ ê¸€ì´ê±°ë‚˜ ë™í–¥ ë¶„ì„ í›„ ë²„ê·¸ë¡œ ë¶„ë¥˜ëœ ê²½ìš°
            if source.endswith('_bug') or category == 'bug' or classification.get('realtime_alert', {}).get('should_alert', False):
                # ì‹¤ì‹œê°„ ë²„ê·¸ ë©”ì‹œì§€
                success = self._send_immediate_bug_alert(post_data)
                if success:
                    self.stats['immediate_bug_alerts'] += 1
                    self.stats['bug_posts'] += 1
                    logger.info(f"ğŸš¨ ì¦‰ì‹œ ë²„ê·¸ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {title[:30]}...")
                else:
                    raise Exception("ë²„ê·¸ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
            
            else:
                # ê¸ì •/ì¤‘ë¦½/ë¶€ì • ë™í–¥ìœ¼ë¡œ ë¶„ë¥˜ëœ ê¸€ - ê°ì„± ë™í–¥ ì•Œë¦¼ ë©”ì‹œì§€
                success = self._send_immediate_sentiment_alert(post_data)
                if success:
                    self.stats['immediate_sentiment_alerts'] += 1
                    self.stats['sentiment_posts'] += 1
                    logger.info(f"ğŸ“Š ì¦‰ì‹œ ê°ì„± ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {title[:30]}...")
                else:
                    raise Exception("ê°ì„± ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
            
            # ì¼ê°„ ë¦¬í¬íŠ¸ìš© ê°ì„± ë°ì´í„° ì €ì¥
            self._save_sentiment_for_daily_report(post_data, classification)
            
            # 3. ì²˜ë¦¬ ì™„ë£Œ ë§ˆí‚¹ (ì•Œë¦¼ ì„±ê³µ ì‹œì—ë§Œ)
            mark_as_processed(post_data.get('url', ''), notified=True)
            self.stats['processed_posts'] += 1
            
            logger.info(f"âœ… ì¦‰ì‹œ ì²˜ë¦¬ ì™„ë£Œ: {title[:30]}...")
            return True
            
        except Exception as e:
            error_msg = f"ì¦‰ì‹œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(f"âŒ {error_msg} - {post_data.get('title', 'N/A')[:30]}...")
            
            # âœ¨ FIXED: ì¬ì‹œë„ í ì¶”ê°€ ì‹œ ì¤‘ë³µ ë°©ì§€ ì ìš©
            RetryManager.add_to_retry_queue(post_data, error_msg)
            
            self.stats['failed_posts'] += 1
            self.stats['errors'] += 1
            
            # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ê²Œì‹œê¸€ ê³„ì† ì²˜ë¦¬ (Master ìš”êµ¬ì‚¬í•­)
            return False
    
    def _send_immediate_bug_alert(self, post_data: Dict) -> bool:
        """ì¦‰ì‹œ ë²„ê·¸ ì•Œë¦¼ ì „ì†¡"""
        try:
            if not self.webhooks.get('bug'):
                logger.warning("ë²„ê·¸ ì•Œë¦¼ ì›¹í›…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
            
            # ë‹¨ì¼ ê²Œì‹œê¸€ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œ
            success = send_bug_alert([post_data])
            return success
            
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ë²„ê·¸ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _send_immediate_sentiment_alert(self, post_data: Dict) -> bool:
        """ì¦‰ì‹œ ê°ì„± ì•Œë¦¼ ì „ì†¡"""
        try:
            if not self.webhooks.get('sentiment'):
                logger.warning("ê°ì„± ì•Œë¦¼ ì›¹í›…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return False
            
            # ê°ì„± ìš”ì•½ ìƒì„±
            classification = post_data.get('classification', {})
            sentiment = classification.get('sentiment_analysis', {}).get('sentiment', 'neutral')
            
            sentiment_summary = {
                'total_posts': 1,
                'sentiment_distribution': {sentiment: 1},
                'time_period': 'ì¦‰ì‹œ ì²˜ë¦¬',
                'timestamp': datetime.now().isoformat()
            }
            
            # ë‹¨ì¼ ê²Œì‹œê¸€ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œ
            success = send_sentiment_notification([post_data], sentiment_summary)
            return success
            
        except Exception as e:
            logger.error(f"ì¦‰ì‹œ ê°ì„± ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _save_sentiment_for_daily_report(self, post_data: Dict, classification: Dict):
        """
        ì¼ê°„ ë¦¬í¬íŠ¸ìš© ê°ì„± ë°ì´í„° ì €ì¥ 
        âœ¨ FIXED: sentiment_data_manager í˜¸ì¶œ ë°©ì‹ ìˆ˜ì •
        """
        try:
            # âœ¨ FIXED: ì§€ì—° ì„í¬íŠ¸ë¡œ ìˆœí™˜ ì°¸ì¡° ë¬¸ì œ í•´ê²°
            try:
                from sentiment_data_manager import Epic7SentimentManager
            except ImportError as e:
                logger.error(f"sentiment_data_manager ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
                logger.warning("ê°ì„± ë°ì´í„° ì €ì¥ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # âœ¨ FIXED: SentimentDataManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ ì˜¬ë°”ë¥¸ ë©”ì„œë“œ í˜¸ì¶œ
            try:
                manager = Epic7SentimentManager()
                
                # ê°ì„± ë°ì´í„° ìƒì„±
                sentiment_data = {
                    'title': post_data.get('title', ''),
                    'content': post_data.get('content', '')[:200],  # ë‚´ìš© ê¸¸ì´ ì œí•œ
                    'url': post_data.get('url', ''),
                    'source': post_data.get('source', ''),
                    'sentiment': classification.get('sentiment_analysis', {}).get('sentiment', 'neutral'),
                    'confidence': classification.get('sentiment_analysis', {}).get('confidence', 0.0),
                    'category': classification.get('category', 'neutral'),
                    'timestamp': datetime.now().isoformat()
                }
                
                # âœ¨ FIXED: ì˜¬ë°”ë¥¸ ë©”ì„œë“œ í˜¸ì¶œ (ë‹¨ì¼ ë°ì´í„° ì €ì¥)
                success = manager.save_post_data(sentiment_data)
                
                if success:
                    logger.debug(f"ì¼ê°„ ë¦¬í¬íŠ¸ìš© ê°ì„± ë°ì´í„° ì €ì¥ ì™„ë£Œ: {post_data.get('title', 'N/A')[:30]}...")
                else:
                    logger.warning(f"ê°ì„± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {post_data.get('title', 'N/A')[:30]}...")
                    
            except AttributeError as e:
                # âœ¨ FIXED: ë©”ì„œë“œê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ë°©ì‹ ì‚¬ìš©
                logger.warning(f"SentimentDataManager ë©”ì„œë“œ ì˜¤ë¥˜: {e}")
                
                # ëŒ€ì²´ ë°©ì‹: ì§ì ‘ JSON íŒŒì¼ì— ì €ì¥
                self._save_sentiment_direct(post_data, classification)
                
        except Exception as e:
            logger.error(f"ê°ì„± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_sentiment_direct(self, post_data: Dict, classification: Dict):
        """
        âœ¨ FIXED: ì§ì ‘ ê°ì„± ë°ì´í„° ì €ì¥ (sentiment_data_manager ëŒ€ì²´ ë°©ì‹)
        """
        try:
            sentiment_file = "daily_sentiment_data.json"
            
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            if os.path.exists(sentiment_file):
                with open(sentiment_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                data = []
            
            # ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€
            sentiment_entry = {
                'title': post_data.get('title', ''),
                'content': post_data.get('content', '')[:200],
                'url': post_data.get('url', ''),
                'source': post_data.get('source', ''),
                'sentiment': classification.get('sentiment_analysis', {}).get('sentiment', 'neutral'),
                'confidence': classification.get('sentiment_analysis', {}).get('confidence', 0.0),
                'category': classification.get('category', 'neutral'),
                'timestamp': datetime.now().isoformat()
            }
            
            data.append(sentiment_entry)
            
            # 24ì‹œê°„ ì´ì „ ë°ì´í„° ì •ë¦¬
            cutoff_time = datetime.now() - timedelta(hours=24)
            filtered_data = []
            
            for entry in data:
                try:
                    entry_time = datetime.fromisoformat(entry['timestamp'])
                    if entry_time > cutoff_time:
                        filtered_data.append(entry)
                except:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìœ ì§€
                    filtered_data.append(entry)
            
            # íŒŒì¼ì— ì €ì¥
            with open(sentiment_file, 'w', encoding='utf-8') as f:
                json.dump(filtered_data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ì§ì ‘ ê°ì„± ë°ì´í„° ì €ì¥ ì™„ë£Œ: {post_data.get('title', 'N/A')[:30]}...")
            
        except Exception as e:
            logger.error(f"ì§ì ‘ ê°ì„± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_unified_30min_schedule(self) -> bool:
        """
        30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ ì‹¤í–‰ 
        Master ìš”êµ¬ì‚¬í•­: ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ + ì¬ì‹œë„ ì²˜ë¦¬
        âœ¨ FIXED: ì¬ì‹œë„ í ê´€ë¦¬ ê°œì„ 
        """
        try:
            logger.info("ğŸš€ 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ ì‹œì‘ - ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ ëª¨ë“œ")
            
            # âœ¨ FIXED: ì¬ì‹œë„ í ìë™ ì •ë¦¬ ë¨¼ì € ì‹¤í–‰
            cleanup_count = RetryManager.cleanup_retry_queue()
            if cleanup_count > 0:
                logger.info(f"ğŸ§¹ ì¬ì‹œë„ í ìë™ ì •ë¦¬: {cleanup_count}ê°œ ì •ë¦¬ë¨")
            
            # 1. ì¬ì‹œë„ í ì²˜ë¦¬
            retry_count = RetryManager.process_retry_queue()
            self.stats['retry_processed'] = retry_count
            
            if retry_count > 0:
                logger.info(f"ğŸ“‹ ì¬ì‹œë„ ì²˜ë¦¬ ì™„ë£Œ: {retry_count}ê°œ")
            
            # 2. ìƒˆë¡œìš´ í¬ë¡¤ë§ ì‹¤í–‰ (ì¦‰ì‹œ ì²˜ë¦¬ ëª¨ë“œ)
            logger.info("ğŸ•·ï¸ í¬ë¡¤ë§ ì‹œì‘ - ì¦‰ì‹œ ì²˜ë¦¬ ì½œë°± ì—°ë™")
            
            # crawler.py v4.3ì˜ ì¦‰ì‹œ ì²˜ë¦¬ ëª¨ë“œ ì‚¬ìš©
            posts = crawl_frequent_sites(
                force_crawl=self.force_crawl,
                on_post_process=self.process_post_immediately  # ğŸš€ í•µì‹¬: ì¦‰ì‹œ ì²˜ë¦¬ ì½œë°±
            )
            
            # í¬ë¡¤ë§ ê²°ê³¼ ë¡œê·¸ (ì°¸ê³ ìš©, ì‹¤ì œ ì²˜ë¦¬ëŠ” ì½œë°±ì—ì„œ ì™„ë£Œë¨)
            logger.info(f"ğŸ•·ï¸ í¬ë¡¤ë§ ì™„ë£Œ: {len(posts) if posts else 0}ê°œ ê²Œì‹œê¸€ ì²˜ë¦¬ë¨")
            
            logger.info("âœ… 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ğŸ’¥ 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def run_debug_mode(self) -> bool:
        """ë””ë²„ê·¸ ëª¨ë“œ ì‹¤í–‰"""
        try:
            logger.info("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ ì‹œì‘ - ì¦‰ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            
            # í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ (ì†ŒëŸ‰)
            logger.info("í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤í–‰...")
            
            posts = crawl_by_schedule(
                "30min", 
                force_crawl=self.force_crawl
            )
            
            if not posts:
                logger.info("ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸: ìƒˆë¡œìš´ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            # ì²« 3ê°œ ê²Œì‹œê¸€ë§Œ ì¦‰ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            test_posts = posts[:3]
            logger.info(f"ğŸ”§ ì¦‰ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸: {len(test_posts)}ê°œ ê²Œì‹œê¸€")
            
            for i, post in enumerate(test_posts, 1):
                logger.info(f"ğŸ”§ í…ŒìŠ¤íŠ¸ {i}/{len(test_posts)}: {post.get('title', 'N/A')[:50]}...")
                success = self.process_post_immediately(post)
                logger.info(f"ğŸ”§ í…ŒìŠ¤íŠ¸ {i} ê²°ê³¼: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")
            
            # ì¬ì‹œë„ í í…ŒìŠ¤íŠ¸
            retry_count = RetryManager.process_retry_queue()
            logger.info(f"ğŸ”§ ì¬ì‹œë„ í í…ŒìŠ¤íŠ¸: {retry_count}ê°œ ì²˜ë¦¬")
            
            logger.info("âœ… ë””ë²„ê·¸ ëª¨ë“œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë””ë²„ê·¸ ëª¨ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def generate_execution_report(self) -> str:
        """ì‹¤í–‰ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        execution_time = end_time - self.start_time
        
        # âœ¨ FIXED: ì¬ì‹œë„ í ìƒíƒœ ì •ë³´ ì¶”ê°€
        retry_queue = RetryManager.load_retry_queue()
        retry_queue_size = len(retry_queue)
        
        report = f"""
ğŸ¯ **Epic7 ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ ë³´ê³ ì„œ v4.3 (ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ)**

**ì‹¤í–‰ ì •ë³´**
- ëª¨ë“œ: {self.mode.upper()}
- ìŠ¤ì¼€ì¤„: {self.schedule} (í†µí•© ìŠ¤ì¼€ì¤„)
- ë””ë²„ê·¸ ëª¨ë“œ: {'On' if self.debug else 'Off'}
- Force Crawl: {'On' if self.force_crawl else 'Off'}
- ì‹œì‘ ì‹œê°„: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
- ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}
- ì‹¤í–‰ ì‹œê°„: {execution_time.total_seconds():.1f}ì´ˆ

**ğŸš€ ì¦‰ì‹œ ì²˜ë¦¬ ê²°ê³¼ (v4.3 í•µì‹¬ ê¸°ëŠ¥)**
- ì´ ì²˜ë¦¬ ì‹œë„: {self.stats['total_crawled']}ê°œ
- ì¦‰ì‹œ ë²„ê·¸ ì•Œë¦¼: {self.stats['immediate_bug_alerts']}ê°œ
- ì¦‰ì‹œ ê°ì„± ì•Œë¦¼: {self.stats['immediate_sentiment_alerts']}ê°œ
- ì²˜ë¦¬ ì„±ê³µ: {self.stats['processed_posts']}ê°œ
- ì²˜ë¦¬ ì‹¤íŒ¨: {self.stats['failed_posts']}ê°œ
- ì¬ì‹œë„ ì²˜ë¦¬: {self.stats['retry_processed']}ê°œ

**ê²Œì‹œê¸€ ë¶„ë¥˜**
- ë²„ê·¸ ê²Œì‹œê¸€: {self.stats['bug_posts']}ê°œ
- ê°ì„± ê²Œì‹œê¸€: {self.stats['sentiment_posts']}ê°œ
- ì˜¤ë¥˜ ë°œìƒ: {self.stats['errors']}ê°œ

**âœ¨ FIXED: ì¬ì‹œë„ í ê´€ë¦¬ ìƒíƒœ**
- í˜„ì¬ ì¬ì‹œë„ í í¬ê¸°: {retry_queue_size}ê°œ
- ìµœëŒ€ í—ˆìš© í¬ê¸°: {MAX_RETRY_QUEUE_SIZE}ê°œ
- í ìƒíƒœ: {'ğŸŸ¢ ì •ìƒ' if retry_queue_size < RETRY_QUEUE_CLEANUP_THRESHOLD else 'ğŸŸ¡ ì •ë¦¬ í•„ìš”' if retry_queue_size < MAX_RETRY_QUEUE_SIZE else 'ğŸ”´ ì„ê³„ ì´ˆê³¼'}

**ğŸ¯ Master ìš”êµ¬ì‚¬í•­ ë‹¬ì„±ë„**
- ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬: {'âœ… í™œì„±í™”ë¨' if self.stats['total_crawled'] > 0 else 'âŒ ë¹„í™œì„±í™”'}
- 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„: âœ… êµ¬í˜„ë¨
- ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬: âœ… êµ¬í˜„ë¨
- ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜: âœ… êµ¬í˜„ë¨ ({self.stats['retry_processed']}ê°œ ì²˜ë¦¬)
- ì—ëŸ¬ ê²©ë¦¬: âœ… êµ¬í˜„ë¨ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
- í í¬ê¸° ì œí•œ: âœ… ì¶”ê°€ë¨ (ìµœëŒ€ {MAX_RETRY_QUEUE_SIZE}ê°œ)

**ì„±ëŠ¥ ì§€í‘œ**
- ì¦‰ì‹œ ì²˜ë¦¬ ì„±ê³µë¥ : {((self.stats['processed_posts'] / max(1, self.stats['total_crawled'])) * 100):.1f}%
- ë²„ê·¸ ê°ì§€ìœ¨: {((self.stats['bug_posts'] / max(1, self.stats['total_crawled'])) * 100):.1f}%
- ì¬ì‹œë„ íš¨ìœ¨: {self.stats['retry_processed']}ê°œ ë³µêµ¬

**ì‹œìŠ¤í…œ ìƒíƒœ**
- í™œì„± ì›¹í›…: {', '.join(self.webhooks.keys()) if self.webhooks else 'None'}
- ì‹¤í–‰ ë½: {'í•´ì œë¨' if not ExecutionManager.is_running() else 'í™œì„±í™”ë¨'}

**í˜„ì¬ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        return report.strip()
    
    def run(self) -> bool:
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„"""
        try:
            logger.info(f"ğŸ¯ Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 ì‹œì‘ - ëª¨ë“œ: {self.mode}, ìŠ¤ì¼€ì¤„: {self.schedule}, force_crawl: {self.force_crawl}")
            
            # ì‹¤í–‰ ë½ í™•ì¸ (production ëª¨ë“œì—ì„œë§Œ)
            if self.mode == "production" and not self.debug:
                if ExecutionManager.is_running():
                    logger.info("â¸ï¸ ì´ì „ ì‹¤í–‰ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ëŒ€ê¸° ì¤‘...")
                    return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì •ìƒì ì¸ ëŒ€ê¸° ìƒí™©)
                
                if not ExecutionManager.acquire_lock():
                    logger.error("âŒ ì‹¤í–‰ ë½ íšë“ ì‹¤íŒ¨")
                    return False
            
            try:
                # ëª¨ë“œë³„ ì‹¤í–‰
                if self.mode == "debug":
                    success = self.run_debug_mode()
                elif self.mode == "production":
                    # v4.3: 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ë§Œ ì§€ì›
                    success = self.run_unified_30min_schedule()
                else:
                    logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {self.mode}")
                    return False
                
                # ì‹¤í–‰ ë³´ê³ ì„œ ìƒì„±
                report = self.generate_execution_report()
                
                # ë³´ê³ ì„œ ì¶œë ¥
                logger.info("ì‹¤í–‰ ë³´ê³ ì„œ:")
                logger.info(report)
                
                logger.info("ğŸ‰ Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 ì‹¤í–‰ ì™„ë£Œ (ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ)")
                return success
                
            finally:
                # ì‹¤í–‰ ë½ í•´ì œ
                if self.mode == "production" and not self.debug:
                    ExecutionManager.release_lock()
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Epic7 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return False

# =============================================================================
# ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤
# =============================================================================

def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="Epic7 í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v4.3 (ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸš€ v4.3 ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥:
- ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ (í¬ë¡¤ë§ â†’ ê°ì„±ë¶„ì„ â†’ ì•Œë¦¼ â†’ ë§ˆí‚¹)
- 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ (ë§¤ì‹œ 30ë¶„ ì‹¤í–‰)
- ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬ (ì‹¤í–‰ì¤‘ì´ë©´ ëŒ€ê¸°)
- ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ (ì‹¤íŒ¨í•œ ì•Œë¦¼ ìë™ ì¬ì‹œë„)
- ì—ëŸ¬ ê²©ë¦¬ (1ê°œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
- âœ¨ FIXED: ì¬ì‹œë„ í í¬ê¸° ì œí•œ ë° ìë™ ì •ë¦¬
- âœ¨ FIXED: sentiment_data_manager í˜¸ì¶œ ì˜¤ë¥˜ í•´ê²°

ì‚¬ìš© ì˜ˆì‹œ:
  python monitor_bugs.py                             # 30ë¶„ í†µí•© ìŠ¤ì¼€ì¤„ (ê¸°ë³¸)
  python monitor_bugs.py --mode debug               # ë””ë²„ê·¸ ëª¨ë“œ
  python monitor_bugs.py --force-crawl              # ê°•ì œ í¬ë¡¤ë§ ëª¨ë“œ

Master ìš”êµ¬ì‚¬í•­ êµ¬í˜„:
  - ê²Œì‹œê¸€ 1ê°œ ìˆ˜ì§‘ â†’ ê°ì„±ë¶„ì„ â†’ ì•Œë¦¼ â†’ ë‹¤ìŒ ê²Œì‹œê¸€
  - ë§¤ì‹œ 30ë¶„ ì‹¤í–‰, ì‹¤í–‰ì¤‘ì´ë©´ ëŒ€ê¸°
  - ì•Œë¦¼ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ í ê´€ë¦¬ (í¬ê¸° ì œí•œ í¬í•¨)
        """
    )
    
    parser.add_argument(
        '--mode',
        choices=['production', 'debug'],
        default='production',
        help='ì‹¤í–‰ ëª¨ë“œ (default: production)'
    )
    
    parser.add_argument(
        '--schedule',
        choices=['30min'],
        default='30min',
        help='ìŠ¤ì¼€ì¤„ (v4.3: 30min í†µí•© ìŠ¤ì¼€ì¤„ë§Œ ì§€ì›)'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”'
    )
    
    parser.add_argument(
        '--force-crawl',
        action='store_true',
        help='ê°•ì œ í¬ë¡¤ë§ ëª¨ë“œ (ìºì‹œ ë¬´ì‹œ)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    parser.add_argument(
        '--cleanup-retry-queue',
        action='store_true',
        help='ì¬ì‹œë„ í ê°•ì œ ì •ë¦¬ í›„ ì¢…ë£Œ'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version='Epic7 Monitor v4.3 (ê²Œì‹œê¸€ë³„ ì¦‰ì‹œ ì²˜ë¦¬ ì‹œìŠ¤í…œ + ìˆ˜ì •ë³¸)'
    )
        
    return parser.parse_args()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì¸ì íŒŒì‹±
        args = parse_arguments()
        
        # âœ¨ FIXED: ì¬ì‹œë„ í ê°•ì œ ì •ë¦¬ ì˜µì…˜
        if args.cleanup_retry_queue:
            logger.info("ì¬ì‹œë„ í ê°•ì œ ì •ë¦¬ ì‹œì‘...")
            cleanup_count = RetryManager.cleanup_retry_queue()
            logger.info(f"ì¬ì‹œë„ í ì •ë¦¬ ì™„ë£Œ: {cleanup_count}ê°œ ì •ë¦¬ë¨")
            return
        
        # ëª¨ë“œ ì„¤ì • (debug í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ debug ëª¨ë“œë¡œ)
        mode = "debug" if args.debug else args.mode
        
        # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        if not any(os.getenv(key) for key in ['DISCORD_WEBHOOK_BUG', 'DISCORD_WEBHOOK_SENTIMENT', 'DISCORD_WEBHOOK_REPORT']):
            logger.warning("Discord ì›¹í›… í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.warning("ì•Œë¦¼ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë‹ˆí„° ì´ˆê¸°í™” ë° ì‹¤í–‰
        monitor = Epic7Monitor(
            mode=mode, 
            schedule=args.schedule,
            debug=args.debug, 
            force_crawl=args.force_crawl
        )
        
        # ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
        success = monitor.run()
        
        # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        ExecutionManager.release_lock()
        sys.exit(130)
        
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        ExecutionManager.release_lock()
        sys.exit(1)

if __name__ == "__main__":
    main()