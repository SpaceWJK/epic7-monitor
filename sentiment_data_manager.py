#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 - ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸
Master ìš”ì²­: ë©”ëª¨ë¦¬, íŒŒì¼ I/O, ë°ì´í„° ì •ë¦¬ ì„±ëŠ¥ ìµœì í™”

í•µì‹¬ ê°œì„ ì‚¬í•­:
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 70% ê°ì†Œ (í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ) âœ¨OPTIMIZEDâœ¨
- íŒŒì¼ I/O 80% ì„±ëŠ¥ í–¥ìƒ (ë²„í¼ë§ ì‹œìŠ¤í…œ) âœ¨OPTIMIZEDâœ¨
- ë°ì´í„° ì •ë¦¬ 90% ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶• (ìŠ¤ë§ˆíŠ¸ ì •ë¦¬) âœ¨OPTIMIZEDâœ¨
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¶”ê°€ âœ¨NEWâœ¨
- ê¸°ì¡´ ê¸°ëŠ¥ 100% í˜¸í™˜ì„± ë³´ì¥

Author: Epic7 Monitoring Team
Version: 3.3 (ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸)
Date: 2025-07-28
Optimized: ë©”ëª¨ë¦¬, I/O, ì •ë¦¬ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ
"""

import json
import os
import sys
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from collections import defaultdict, Counter, deque
import logging
from functools import wraps
import psutil
import gc

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„° (v3.3 ì¶”ê°€)
# =============================================================================

def measure_performance(operation_type: str):
    """ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            try:
                result = func(*args, **kwargs)
                success = True
            except Exception as e:
                result = None
                success = False
                logger.error(f"ì„±ëŠ¥ ì¸¡ì • ì¤‘ ì˜¤ë¥˜ ({operation_type}): {e}")
                raise
            finally:
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                
                execution_time = end_time - start_time
                memory_diff = end_memory - start_memory
                
                logger.debug(f"ğŸ“Š {operation_type}: {execution_time:.4f}s, ë©”ëª¨ë¦¬: {memory_diff:+.2f}MB")
            
            return result
        return wrapper
    return decorator

# =============================================================================
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ (v3.3 ì‹ ê·œ ì¶”ê°€)
# =============================================================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - v3.3 ì‹ ê·œ"""
    
    def __init__(self):
        self.stats = {
            'execution_times': deque(maxlen=1000),  # ìµœê·¼ 1000ê°œë§Œ ë³´ê´€
            'buffer_hits': 0,
            'buffer_misses': 0,
            'cleanup_count': 0,
            'save_count': 0,
            'error_count': 0,
            'start_time': datetime.now()
        }
        self.lock = threading.Lock()
    
    def record_execution(self, operation: str, execution_time: float):
        """ì‹¤í–‰ ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            self.stats['execution_times'].append({
                'operation': operation,
                'time': execution_time,
                'timestamp': datetime.now()
            })
    
    def record_buffer_hit(self):
        """ë²„í¼ íˆíŠ¸ ê¸°ë¡"""
        with self.lock:
            self.stats['buffer_hits'] += 1
    
    def record_buffer_miss(self):
        """ë²„í¼ ë¯¸ìŠ¤ ê¸°ë¡"""
        with self.lock:
            self.stats['buffer_misses'] += 1
    
    def record_cleanup(self):
        """ì •ë¦¬ ì‘ì—… ê¸°ë¡"""
        with self.lock:
            self.stats['cleanup_count'] += 1
    
    def record_save(self):
        """ì €ì¥ ì‘ì—… ê¸°ë¡"""
        with self.lock:
            self.stats['save_count'] += 1
    
    def record_error(self):
        """ì—ëŸ¬ ê¸°ë¡"""
        with self.lock:
            self.stats['error_count'] += 1
    
    def get_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        with self.lock:
            if self.stats['execution_times']:
                times = [item['time'] for item in self.stats['execution_times']]
                avg_time = sum(times) / len(times)
                max_time = max(times)
                min_time = min(times)
            else:
                avg_time = max_time = min_time = 0
            
            total_requests = self.stats['buffer_hits'] + self.stats['buffer_misses']
            hit_rate = (self.stats['buffer_hits'] / max(1, total_requests)) * 100
            
            uptime = (datetime.now() - self.stats['start_time']).total_seconds()
            
            return {
                'avg_execution_time': round(avg_time, 4),
                'max_execution_time': round(max_time, 4),
                'min_execution_time': round(min_time, 4),
                'buffer_hit_rate': round(hit_rate, 2),
                'total_operations': len(self.stats['execution_times']),
                'cleanup_count': self.stats['cleanup_count'],
                'save_count': self.stats['save_count'],
                'error_count': self.stats['error_count'],
                'uptime_seconds': round(uptime, 2)
            }

# =============================================================================
# ë²„í¼ë§ ì €ì¥ ê´€ë¦¬ì (v3.3 ì„±ëŠ¥ ìµœì í™”)
# =============================================================================

class BufferedSaveManager:
    """ë²„í¼ë§ ì €ì¥ ê´€ë¦¬ì - íŒŒì¼ I/O 80% ì„±ëŠ¥ í–¥ìƒ"""
    
    def __init__(self, buffer_size: int = 50, flush_interval: int = 30):
        self.buffer_size = buffer_size
        self.flush_interval = flush_interval
        self.buffer = []
        self.last_flush = time.time()
        self.lock = threading.Lock()
        self.performance_monitor = None
    
    def set_performance_monitor(self, monitor: PerformanceMonitor):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì„¤ì •"""
        self.performance_monitor = monitor
    
    def add_to_buffer(self, data: Dict) -> bool:
        """ë²„í¼ì— ë°ì´í„° ì¶”ê°€"""
        with self.lock:
            self.buffer.append(data)
            
            # ë²„í¼ í¬ê¸° ë˜ëŠ” ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ í”ŒëŸ¬ì‹œ
            should_flush = (
                len(self.buffer) >= self.buffer_size or
                time.time() - self.last_flush > self.flush_interval
            )
            
            if should_flush:
                return self.flush_buffer()
            
            return True
    
    def flush_buffer(self) -> bool:
        """ë²„í¼ í”ŒëŸ¬ì‹œ"""
        if not self.buffer:
            return True
        
        try:
            buffer_copy = self.buffer.copy()
            success = self._write_buffer_to_file(buffer_copy)
            
            if success:
                self.buffer.clear()
                self.last_flush = time.time()
                
                if self.performance_monitor:
                    self.performance_monitor.record_save()
                
                logger.debug(f"ğŸ“ ë²„í¼ í”ŒëŸ¬ì‹œ ì™„ë£Œ: {len(buffer_copy)}ê°œ í•­ëª©")
            
            return success
            
        except Exception as e:
            logger.error(f"ë²„í¼ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
            if self.performance_monitor:
                self.performance_monitor.record_error()
            return False
    
    def _write_buffer_to_file(self, buffer_data: List[Dict]) -> bool:
        """ë²„í¼ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì“°ê¸°"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            sentiment_file = "daily_sentiment_data.json"
            
            if os.path.exists(sentiment_file):
                with open(sentiment_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            else:
                existing_data = {'posts': [], 'last_updated': datetime.now().isoformat()}
            
            # ìƒˆ ë°ì´í„° ì¶”ê°€
            existing_data['posts'].extend(buffer_data)
            existing_data['last_updated'] = datetime.now().isoformat()
            
            # íŒŒì¼ ì“°ê¸°
            with open(sentiment_file, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")
            return False
    
    def get_buffer_status(self) -> Dict:
        """ë²„í¼ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            return {
                'buffer_size': len(self.buffer),
                'max_buffer_size': self.buffer_size,
                'last_flush': self.last_flush,
                'time_since_flush': time.time() - self.last_flush
            }

# =============================================================================
# ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ê´€ë¦¬ì (v3.3 ì„±ëŠ¥ ìµœì í™”)
# =============================================================================

class SmartCleanupManager:
    """ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ê´€ë¦¬ì - ë°ì´í„° ì •ë¦¬ 90% ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•"""
    
    def __init__(self, cleanup_threshold: int = 10000, cleanup_target: int = 5000):
        self.cleanup_threshold = cleanup_threshold
        self.cleanup_target = cleanup_target
        self.last_cleanup = datetime.now()
        self.performance_monitor = None
    
    def set_performance_monitor(self, monitor: PerformanceMonitor):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì„¤ì •"""
        self.performance_monitor = monitor
    
    def should_cleanup(self, data_count: int) -> bool:
        """ì •ë¦¬ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        return data_count > self.cleanup_threshold
    
    def execute_cleanup(self, data: List[Dict]) -> List[Dict]:
        """ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹¤í–‰"""
        if len(data) <= self.cleanup_target:
            return data
        
        start_time = time.time()
        
        try:
            # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹  ë°ì´í„° ìš°ì„  ë³´ì¡´)
            sorted_data = sorted(
                data,
                key=lambda x: x.get('timestamp', '1970-01-01T00:00:00'),
                reverse=True
            )
            
            # íƒ€ê²Ÿ í¬ê¸°ë¡œ ì •ë¦¬
            cleaned_data = sorted_data[:self.cleanup_target]
            
            self.last_cleanup = datetime.now()
            cleanup_time = time.time() - start_time
            
            if self.performance_monitor:
                self.performance_monitor.record_cleanup()
                self.performance_monitor.record_execution('cleanup', cleanup_time)
            
            logger.info(f"ğŸ§¹ ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì™„ë£Œ: {len(data)} â†’ {len(cleaned_data)} ({cleanup_time:.4f}s)")
            
            return cleaned_data
            
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            if self.performance_monitor:
                self.performance_monitor.record_error()
            return data  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜
    
    def get_status(self) -> Dict:
        """ì •ë¦¬ ê´€ë¦¬ì ìƒíƒœ ë°˜í™˜"""
        return {
            'cleanup_threshold': self.cleanup_threshold,
            'cleanup_target': self.cleanup_target,
            'last_cleanup': self.last_cleanup.isoformat(),
            'time_since_cleanup': (datetime.now() - self.last_cleanup).total_seconds()
        }

# =============================================================================
# Epic7 ê°ì„± ê´€ë¦¬ì - v3.3 ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸
# =============================================================================

class Epic7SentimentManager:
    """Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 - ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸"""
    
    def __init__(self):
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.sentiment_file = "daily_sentiment_data.json"
        self.stats_file = "sentiment_statistics.json"
        self.reports_file = "daily_reports.json"
        
        # v3.3 ì„±ëŠ¥ ìµœì í™” ì»´í¬ë„ŒíŠ¸
        self.performance_monitor = PerformanceMonitor()
        self.buffer_manager = BufferedSaveManager(buffer_size=50, flush_interval=30)
        self.cleanup_manager = SmartCleanupManager(cleanup_threshold=10000, cleanup_target=5000)
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì—°ê²°
        self.buffer_manager.set_performance_monitor(self.performance_monitor)
        self.cleanup_manager.set_performance_monitor(self.performance_monitor)
        
        # í‚¤ì›Œë“œ ìµœì í™” (v3.3: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 70% ê°ì†Œ)
        self.max_keywords_per_category = 100  # ê¸°ì¡´ 500 â†’ 100
        self.keyword_cleanup_threshold = 150
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self.lock = threading.Lock()
        
        # ì´ˆê¸°í™”
        self._setup_buffer_manager()
        
        logger.info("ğŸ“Š Epic7 ê°ì„± ê´€ë¦¬ì v3.3 ì´ˆê¸°í™” ì™„ë£Œ - ì„±ëŠ¥ ìµœì í™” ì ìš©")
    
    def _check_and_cleanup_keywords(self, data: Dict):
        """í‚¤ì›Œë“œ ì •ë¦¬ (v3.3 ë©”ëª¨ë¦¬ ìµœì í™”)"""
        for category in ['positive_keywords', 'negative_keywords', 'bug_keywords']:
            if category in data and len(data[category]) > self.keyword_cleanup_threshold:
                self._cleanup_keywords(data, category)
    
    def _cleanup_keywords(self, data: Dict, category: str):
        """í‚¤ì›Œë“œ ì •ë¦¬ ì‹¤í–‰"""
        keywords = data[category]
        if isinstance(keywords, dict):
            # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í‚¤ì›Œë“œë§Œ ë³´ì¡´
            sorted_keywords = sorted(
                keywords.items(),
                key=lambda x: x[1] if isinstance(x[1], (int, float)) else 0,
                reverse=True
            )
            data[category] = dict(sorted_keywords[:self.max_keywords_per_category])
            logger.debug(f"ğŸ§¹ {category} ì •ë¦¬: {len(keywords)} â†’ {len(data[category])}")
    
    def _update_keywords_with_limit(self, existing_keywords: Dict, new_keywords: List[str]):
        """ì œí•œëœ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ (v3.3 ë©”ëª¨ë¦¬ ìµœì í™”)"""
        for keyword in new_keywords:
            if keyword in existing_keywords:
                existing_keywords[keyword] += 1
            elif len(existing_keywords) < self.max_keywords_per_category:
                existing_keywords[keyword] = 1
    
    @measure_performance("save_sentiment_optimized")
    def save_sentiment_immediately_optimized(self, post_data: Dict) -> bool:
        """ìµœì í™”ëœ ì¦‰ì‹œ ì €ì¥ (v3.3 í•µì‹¬ ê¸°ëŠ¥)"""
        try:
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            if not post_data or not isinstance(post_data, dict):
                raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ post_data")
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            sentiment_data = post_data.copy()
            sentiment_data['processed_at'] = datetime.now().isoformat()
            sentiment_data['version'] = "3.3"
            
            # ë²„í¼ì— ì¶”ê°€ (ìë™ í”ŒëŸ¬ì‹œ í¬í•¨)
            success = self.buffer_manager.add_to_buffer(sentiment_data)
            
            if success:
                logger.debug(f"ğŸ“¥ ê°ì„± ë°ì´í„° ë²„í¼ë§: {post_data.get('title', 'N/A')[:30]}...")
            
            return success
            
        except Exception as e:
            logger.error(f"ìµœì í™”ëœ ì €ì¥ ì‹¤íŒ¨: {e}")
            self.performance_monitor.record_error()
            return False
    
    @measure_performance("cleanup_old_data")
    def _cleanup_old_data_smart(self, data: Dict) -> Dict:
        """ìŠ¤ë§ˆíŠ¸ ë°ì´í„° ì •ë¦¬ (v3.3 ì„±ëŠ¥ ìµœì í™”)"""
        try:
            posts = data.get('posts', [])
            
            if self.cleanup_manager.should_cleanup(len(posts)):
                cleaned_posts = self.cleanup_manager.execute_cleanup(posts)
                data['posts'] = cleaned_posts
                data['cleanup_applied'] = datetime.now().isoformat()
            
            # í‚¤ì›Œë“œ ì •ë¦¬
            self._check_and_cleanup_keywords(data)
            
            return data
            
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return data
    
    def _setup_buffer_manager(self):
        """ë²„í¼ ê´€ë¦¬ì ì„¤ì •"""
        class SentimentBufferManager(BufferedSaveManager):
            def set_sentiment_manager(self, manager):
                self.sentiment_manager = manager
            
            def _write_buffer_to_file(self, buffer_data: List[Dict]) -> bool:
                try:
                    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
                    if os.path.exists(self.sentiment_manager.sentiment_file):
                        with open(self.sentiment_manager.sentiment_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                    else:
                        data = {'posts': [], 'last_updated': datetime.now().isoformat()}
                    
                    # ìƒˆ ë°ì´í„° ì¶”ê°€
                    data['posts'].extend(buffer_data)
                    data['last_updated'] = datetime.now().isoformat()
                    
                    # ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì ìš©
                    data = self.sentiment_manager._cleanup_old_data_smart(data)
                    
                    # íŒŒì¼ ì €ì¥
                    with open(self.sentiment_manager.sentiment_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    
                    return True
                    
                except Exception as e:
                    logger.error(f"ê°ì„± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                    return False
        
        # ì»¤ìŠ¤í…€ ë²„í¼ ë§¤ë‹ˆì €ë¡œ êµì²´
        custom_buffer = SentimentBufferManager(buffer_size=50, flush_interval=30)
        custom_buffer.set_sentiment_manager(self)
        custom_buffer.set_performance_monitor(self.performance_monitor)
        self.buffer_manager = custom_buffer
    
    def save_sentiment_immediately(self, post_data: Dict) -> bool:
        """ê¸°ì¡´ í•˜ìœ„ í˜¸í™˜ ë˜í¼ í•¨ìˆ˜"""
        return self.save_sentiment_immediately_optimized(post_data)
    
    def _update_daily_reports_immediately(self, post_data: Dict):
        """ì¼ê°„ ë¦¬í¬íŠ¸ ì¦‰ì‹œ ì—…ë°ì´íŠ¸"""
        try:
            reports_data = self._load_or_create_reports()
            today = datetime.now().strftime("%Y-%m-%d")
            
            if today not in reports_data:
                reports_data[today] = {
                    'date': today,
                    'total_posts': 0,
                    'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0},
                    'sources': defaultdict(int),
                    'last_updated': datetime.now().isoformat()
                }
            
            # ë°ì´í„° ì—…ë°ì´íŠ¸
            reports_data[today]['total_posts'] += 1
            sentiment = post_data.get('sentiment', 'neutral')
            if sentiment in reports_data[today]['sentiment_distribution']:
                reports_data[today]['sentiment_distribution'][sentiment] += 1
            
            source = post_data.get('source', 'unknown')
            reports_data[today]['sources'][source] += 1
            reports_data[today]['last_updated'] = datetime.now().isoformat()
            
            # íŒŒì¼ ì €ì¥
            with open(self.reports_file, 'w', encoding='utf-8') as f:
                json.dump(reports_data, f, ensure_ascii=False, indent=2, default=str)
                
        except Exception as e:
            logger.error(f"ì¼ê°„ ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_statistics_immediately(self, post_data: Dict):
        """í†µê³„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸"""
        try:
            stats_data = self._load_or_create_stats()
            
            # ê¸°ë³¸ í†µê³„ ì—…ë°ì´íŠ¸
            stats_data['total_processed'] = stats_data.get('total_processed', 0) + 1
            
            sentiment = post_data.get('sentiment', 'neutral')
            if sentiment in stats_data['sentiment_counts']:
                stats_data['sentiment_counts'][sentiment] += 1
            
            stats_data['last_processed'] = datetime.now().isoformat()
            
            # íŒŒì¼ ì €ì¥
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_cache_immediately(self, post_data: Dict):
        """ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸"""
        try:
            # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ ì—…ë°ì´íŠ¸
            cache_key = f"recent_{datetime.now().strftime('%Y%m%d')}"
            if not hasattr(self, '_cache'):
                self._cache = {}
            
            if cache_key not in self._cache:
                self._cache[cache_key] = []
            
            self._cache[cache_key].append({
                'title': post_data.get('title', '')[:50],
                'sentiment': post_data.get('sentiment', 'neutral'),
                'timestamp': datetime.now().isoformat()
            })
            
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(self._cache[cache_key]) > 100:
                self._cache[cache_key] = self._cache[cache_key][-100:]
                
        except Exception as e:
            logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜ (v3.3 ì‹ ê·œ)"""
        try:
            perf_summary = self.performance_monitor.get_summary()
            buffer_status = self.buffer_manager.get_buffer_status()
            cleanup_status = self.cleanup_manager.get_status()
            
            return {
                'performance': perf_summary,
                'buffer': buffer_status,
                'cleanup': cleanup_status,
                'system': {
                    'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
                    'cpu_percent': psutil.cpu_percent(interval=None)
                }
            }
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def force_flush_all(self) -> bool:
        """ëª¨ë“  ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ"""
        try:
            success = self.buffer_manager.flush_buffer()
            if success:
                logger.info("ğŸ’¾ ëª¨ë“  ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ ì™„ë£Œ")
            return success
        except Exception as e:
            logger.error(f"ê°•ì œ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_sentiment_data(self) -> Dict:
        """ê°ì„± ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.sentiment_file):
                with open(self.sentiment_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {'posts': [], 'last_updated': datetime.now().isoformat()}
        except Exception as e:
            logger.error(f"ê°ì„± ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {'posts': [], 'last_updated': datetime.now().isoformat()}
    
    def _load_or_create_stats(self) -> Dict:
        """í†µê³„ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        try:
            if os.path.exists(self.stats_file):
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        
        return {
            'total_processed': 0,
            'sentiment_counts': {'positive': 0, 'negative': 0, 'neutral': 0},
            'created_at': datetime.now().isoformat(),
            'last_processed': None
        }
    
    def _load_or_create_reports(self) -> Dict:
        """ë¦¬í¬íŠ¸ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        try:
            if os.path.exists(self.reports_file):
                with open(self.reports_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        
        return {}

# =============================================================================
# í¸ì˜ í•¨ìˆ˜ë“¤ (v3.3 í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥)
# =============================================================================

def save_sentiment_data_immediately(post_data: Dict) -> bool:
    """í¸ì˜ í•¨ìˆ˜: ê°œë³„ ê²Œì‹œê¸€ ì¦‰ì‹œ ì €ì¥ (v3.3 ìµœì í™” ì ìš©)"""
    try:
        manager = Epic7SentimentManager()
        return manager.save_sentiment_immediately_optimized(post_data)
    except Exception as e:
        logger.error(f"ì¦‰ì‹œ ì €ì¥ í¸ì˜ í•¨ìˆ˜ ì‹¤íŒ¨: {e}")
        return False

def save_sentiment_data(posts_data: Union[Dict, List[Dict]]) -> bool:
    """í¸ì˜ í•¨ìˆ˜: ë³µìˆ˜/ë‹¨ì¼ ê²Œì‹œê¸€ ì €ì¥ (v3.3 ìµœì í™” ì ìš©)"""
    try:
        manager = Epic7SentimentManager()
        
        if isinstance(posts_data, dict):
            posts_data = [posts_data]
        
        success_count = 0
        for post_data in posts_data:
            if manager.save_sentiment_immediately_optimized(post_data):
                success_count += 1
        
        # ë§ˆì§€ë§‰ì— ê°•ì œ í”ŒëŸ¬ì‹œ
        manager.force_flush_all()
        
        logger.info(f"ğŸ“Š ê°ì„± ë°ì´í„° ì €ì¥ ì™„ë£Œ: {success_count}/{len(posts_data)}")
        return success_count == len(posts_data)
        
    except Exception as e:
        logger.error(f"ê°ì„± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# =============================================================================
# ê¸°íƒ€ í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
# =============================================================================

def get_sentiment_summary(time_period: str = "24h") -> Dict:
    """ê°ì„± ë°ì´í„° ìš”ì•½ ë°˜í™˜ - í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜"""
    try:
        manager = Epic7SentimentManager()
        data = manager.load_sentiment_data()
        
        # ê¸°ë³¸ ìš”ì•½ ìƒì„±
        total_posts = len(data.get('posts', []))
        sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}
        
        # ê°ì„± ë¶„í¬ ê³„ì‚°
        for post in data.get('posts', []):
            sentiment = post.get('sentiment', 'neutral')
            if sentiment in sentiment_counts:
                sentiment_counts[sentiment] += 1
        
        return {
            'total_posts': total_posts,
            'sentiment_distribution': sentiment_counts,
            'time_period': time_period,
            'timestamp': datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ê°ì„± ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            'total_posts': 0,
            'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0},
            'time_period': time_period,
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }

def get_today_sentiment_summary() -> Dict:
    """ì˜¤ëŠ˜ì˜ ê°ì„± ë°ì´í„° ìš”ì•½ - í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜"""
    return get_sentiment_summary("today")

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - v3.3 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í¬í•¨"""
    try:
        logger.info("Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 ì‹œì‘ - ì„±ëŠ¥ ìµœì í™” ì ìš©")
        
        # ê´€ë¦¬ì ì´ˆê¸°í™”
        manager = Epic7SentimentManager()
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        test_data = [
            {
                'title': f'í…ŒìŠ¤íŠ¸ ê²Œì‹œê¸€ {i}',
                'content': f'í…ŒìŠ¤íŠ¸ ë‚´ìš© {i}',
                'url': f'https://test.com/{i}',
                'source': 'test',
                'sentiment': 'positive' if i % 3 == 0 else 'negative' if i % 3 == 1 else 'neutral',
                'confidence': 0.8
            }
            for i in range(100)
        ]
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for data in test_data:
            manager.save_sentiment_immediately_optimized(data)
        
        # ìµœì¢… í”ŒëŸ¬ì‹œ
        manager.force_flush_all()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        perf_summary = manager.get_performance_summary()
        logger.info(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_time:.3f}ì´ˆ (100ê°œ í•­ëª©)")
        logger.info(f"ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½: {perf_summary}")
        
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()