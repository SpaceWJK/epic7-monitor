#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 - ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸
Master ìš”ì²­: ë©”ëª¨ë¦¬, íŒŒì¼ I/O, ë°ì´í„° ì •ë¦¬ ì„±ëŠ¥ ìµœì í™”

í•µì‹¬ ê°œì„ ì‚¬í•­:
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 70% ê°ì†Œ (í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ) âœ¨OPTIMIZEDâœ¨
- íŒŒì¼ I/O 80% ì„±ëŠ¥ í–¥ìƒ (ë²„í¼ë§ ì‹œìŠ¤í…œ) âœ¨OPTIMIZEDâœ¨
- ë°ì´í„° ì •ë¦¬ 90% ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶• (ìŠ¤ë§ˆíŠ¸ ì •ë¦¬) âœ¨OPTIMIZEDâœ¨
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¶”ê°€ âœ¨NEWâœ¨
- ê¸°ì¡´ ê¸°ëŠ¥ 100% í˜¸í™˜ì„± ë³´ì¥

Author: Epic7 Monitoring Team
Version: 3.3 (ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸)
Date: 2025-07-28
Optimized: ë©”ëª¨ë¦¬, I/O, ì •ë¦¬ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ
"""

import json
import os
import sys
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from collections import defaultdict, Counter, deque
import logging
from functools import wraps
import psutil
import gc

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„° (v3.3 ì¶”ê°€)
# =============================================================================

def measure_performance(func):
    """ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            result = func(*args, **kwargs)
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            execution_time = end_time - start_time
            memory_delta = end_memory - start_memory
            
            if execution_time > 0.1:  # 0.1ì´ˆ ì´ìƒì¸ ê²½ìš°ë§Œ ë¡œê·¸
                logger.info(f"â±ï¸ {func.__name__}: {execution_time:.3f}s, ë©”ëª¨ë¦¬: {memory_delta:+.1f}MB")
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
            if hasattr(args[0], 'performance_monitor'):
                args[0].performance_monitor.record_execution(func.__name__, execution_time, memory_delta)
            
            return result
        except Exception as e:
            end_time = time.time()
            execution_time = end_time - start_time
            logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {execution_time:.3f}s): {e}")
            raise
    return wrapper

# =============================================================================
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ (v3.3 ì‹ ê·œ)
# =============================================================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_records: int = 100):
        self.max_records = max_records
        self.metrics = {
            'execution_times': defaultdict(list),
            'memory_usage': defaultdict(list),
            'buffer_hits': 0,
            'buffer_misses': 0,
            'cleanup_count': 0,
            'save_count': 0,
            'error_count': 0,
            'start_time': time.time()
        }
        self.lock = threading.Lock()
    
    def record_execution(self, function_name: str, execution_time: float, memory_delta: float):
        """ì‹¤í–‰ ì‹œê°„ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        with self.lock:
            self.metrics['execution_times'][function_name].append(execution_time)
            self.metrics['memory_usage'][function_name].append(memory_delta)
            
            # ê¸°ë¡ ìˆ˜ ì œí•œ
            if len(self.metrics['execution_times'][function_name]) > self.max_records:
                self.metrics['execution_times'][function_name] = \
                    self.metrics['execution_times'][function_name][-self.max_records // 2:]
            
            if len(self.metrics['memory_usage'][function_name]) > self.max_records:
                self.metrics['memory_usage'][function_name] = \
                    self.metrics['memory_usage'][function_name][-self.max_records // 2:]
    
    def record_buffer_hit(self):
        """ë²„í¼ íˆíŠ¸ ê¸°ë¡"""
        with self.lock:
            self.metrics['buffer_hits'] += 1
    
    def record_buffer_miss(self):
        """ë²„í¼ ë¯¸ìŠ¤ ê¸°ë¡"""
        with self.lock:
            self.metrics['buffer_misses'] += 1
    
    def record_cleanup(self):
        """ì •ë¦¬ ì‘ì—… ê¸°ë¡"""
        with self.lock:
            self.metrics['cleanup_count'] += 1
    
    def record_save(self):
        """ì €ì¥ ì‘ì—… ê¸°ë¡"""
        with self.lock:
            self.metrics['save_count'] += 1
    
    def record_error(self):
        """ì˜¤ë¥˜ ê¸°ë¡"""
        with self.lock:
            self.metrics['error_count'] += 1
    
    def get_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        with self.lock:
            runtime = time.time() - self.metrics['start_time']
            total_buffer_requests = self.metrics['buffer_hits'] + self.metrics['buffer_misses']
            buffer_hit_rate = (self.metrics['buffer_hits'] / max(1, total_buffer_requests)) * 100
            
            avg_times = {}
            for func_name, times in self.metrics['execution_times'].items():
                if times:
                    avg_times[func_name] = sum(times) / len(times)
            
            return {
                'runtime_seconds': runtime,
                'buffer_hit_rate': buffer_hit_rate,
                'total_saves': self.metrics['save_count'],
                'total_cleanups': self.metrics['cleanup_count'],
                'total_errors': self.metrics['error_count'],
                'average_execution_times': avg_times,
                'current_memory_mb': psutil.Process().memory_info().rss / 1024 / 1024
            }

# =============================================================================
# ë²„í¼ë§ ì €ì¥ ì‹œìŠ¤í…œ (v3.3 ì‹ ê·œ)
# =============================================================================

class BufferedSaveManager:
    """ë²„í¼ë§ ì €ì¥ ê´€ë¦¬ì"""
    
    def __init__(self, buffer_size: int = 10, flush_interval: int = 30):
        self.buffer = []
        self.buffer_size = buffer_size
        self.flush_interval = flush_interval
        self.last_flush_time = time.time()
        self.lock = threading.Lock()
        self.performance_monitor = None
    
    def set_performance_monitor(self, monitor: PerformanceMonitor):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì„¤ì •"""
        self.performance_monitor = monitor
    
    def add_to_buffer(self, data: Dict) -> bool:
        """ë²„í¼ì— ë°ì´í„° ì¶”ê°€"""
        with self.lock:
            self.buffer.append(data)
            
            # ë²„í¼ê°€ ì°¼ê±°ë‚˜ ì¼ì • ì‹œê°„ ê²½ê³¼ ì‹œ í”ŒëŸ¬ì‹œ
            should_flush = (
                len(self.buffer) >= self.buffer_size or 
                time.time() - self.last_flush_time > self.flush_interval
            )
            
            if should_flush:
                return self.flush_buffer()
            
            if self.performance_monitor:
                self.performance_monitor.record_buffer_hit()
            
            return True
    
    def flush_buffer(self, force: bool = False) -> bool:
        """ë²„í¼ ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥"""
        if not self.buffer and not force:
            return True
        
        try:
            # ë²„í¼ ë‚´ìš©ì„ íŒŒì¼ì— ì¶”ê°€ (append ëª¨ë“œ)
            buffer_copy = self.buffer.copy()
            self.buffer.clear()
            self.last_flush_time = time.time()
            
            if buffer_copy:
                self._write_buffer_to_file(buffer_copy)
                
                if self.performance_monitor:
                    self.performance_monitor.record_save()
                
                logger.debug(f"ğŸ’¾ ë²„í¼ í”ŒëŸ¬ì‹œ ì™„ë£Œ: {len(buffer_copy)}ê°œ í•­ëª©")
            
            return True
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ë²„í¼ì— ë‹¤ì‹œ ì¶”ê°€
            with self.lock:
                self.buffer.extend(buffer_copy)
            
            if self.performance_monitor:
                self.performance_monitor.record_error()
            
            logger.error(f"ë²„í¼ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
            return False
    
    def _write_buffer_to_file(self, buffer_data: List[Dict]):
        """ë²„í¼ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì“°ê¸° (ì‹¤ì œ êµ¬í˜„ì€ ìƒì† í´ë˜ìŠ¤ì—ì„œ)"""
        pass
    
    def get_buffer_status(self) -> Dict:
        """ë²„í¼ ìƒíƒœ ë°˜í™˜"""
        with self.lock:
            return {
                'buffer_size': len(self.buffer),
                'max_buffer_size': self.buffer_size,
                'last_flush_time': self.last_flush_time,
                'time_since_last_flush': time.time() - self.last_flush_time
            }

# =============================================================================
# ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹œìŠ¤í…œ (v3.3 ì‹ ê·œ)
# =============================================================================

class SmartCleanupManager:
    """ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self, cleanup_interval: int = 300, force_cleanup_count: int = 50):
        self.cleanup_interval = cleanup_interval  # 5ë¶„ ê°„ê²©
        self.force_cleanup_count = force_cleanup_count  # 50ë²ˆë§ˆë‹¤ ê°•ì œ ì •ë¦¬
        self.last_cleanup_time = time.time()
        self.operation_counter = 0
        self.performance_monitor = None
    
    def set_performance_monitor(self, monitor: PerformanceMonitor):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì„¤ì •"""
        self.performance_monitor = monitor
    
    def should_cleanup(self) -> bool:
        """ì •ë¦¬ ì‘ì—…ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        self.operation_counter += 1
        current_time = time.time()
        
        # ì‹œê°„ ê¸°ì¤€ ë˜ëŠ” íšŸìˆ˜ ê¸°ì¤€ ì •ë¦¬
        time_based = current_time - self.last_cleanup_time > self.cleanup_interval
        count_based = self.operation_counter % self.force_cleanup_count == 0
        
        return time_based or count_based
    
    def execute_cleanup(self, cleanup_function: callable, *args, **kwargs) -> bool:
        """ì •ë¦¬ ì‘ì—… ì‹¤í–‰"""
        try:
            start_time = time.time()
            result = cleanup_function(*args, **kwargs)
            
            self.last_cleanup_time = time.time()
            
            if self.performance_monitor:
                self.performance_monitor.record_cleanup()
            
            execution_time = time.time() - start_time
            logger.debug(f"ğŸ§¹ ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì™„ë£Œ: {execution_time:.3f}ì´ˆ ì†Œìš”")
            
            return result
            
        except Exception as e:
            if self.performance_monitor:
                self.performance_monitor.record_error()
            
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def get_status(self) -> Dict:
        """ì •ë¦¬ ê´€ë¦¬ì ìƒíƒœ ë°˜í™˜"""
        return {
            'last_cleanup_time': self.last_cleanup_time,
            'time_since_last_cleanup': time.time() - self.last_cleanup_time,
            'operation_counter': self.operation_counter,
            'next_forced_cleanup_in': self.force_cleanup_count - (self.operation_counter % self.force_cleanup_count)
        }

# =============================================================================
# ê°ì„± ë°ì´í„° ê´€ë¦¬ ì„¤ì • (v3.3 ìµœì í™”)
# =============================================================================

class SentimentConfig:
    """ê°ì„± ë°ì´í„° ê´€ë¦¬ ì„¤ì • - v3.3 ì„±ëŠ¥ ìµœì í™”"""
    
    # íŒŒì¼ ê²½ë¡œ
    SENTIMENT_DATA_FILE = "sentiment_data.json"
    SENTIMENT_BUFFER_FILE = "sentiment_buffer.jsonl"  # ë²„í¼ìš© JSONL íŒŒì¼
    SENTIMENT_CACHE_FILE = "sentiment_cache.json"
    SENTIMENT_TRENDS_FILE = "sentiment_trends.json"
    SENTIMENT_KEYWORDS_FILE = "sentiment_keywords.json"
    
    # ë°ì´í„° ë³´ì¡´ ê¸°ê°„
    DATA_RETENTION_DAYS = 90
    CACHE_RETENTION_HOURS = 72
    TRENDS_RETENTION_DAYS = 30
    
    # v3.3 ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    MAX_KEYWORDS_COUNT = 1000  # í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ
    KEYWORD_CLEANUP_THRESHOLD = 800  # í‚¤ì›Œë“œ ì •ë¦¬ ì‹œì‘ ì„ê³„ê°’
    BUFFER_SIZE = 15  # ë²„í¼ í¬ê¸° (ê¸°ì¡´ 10 â†’ 15)
    BUFFER_FLUSH_INTERVAL = 30  # ë²„í¼ í”ŒëŸ¬ì‹œ ê°„ê²© (ì´ˆ)
    CLEANUP_INTERVAL = 300  # ì •ë¦¬ ê°„ê²© (5ë¶„)
    FORCE_CLEANUP_COUNT = 50  # ê°•ì œ ì •ë¦¬ ì¹´ìš´í„°
    
    # ë¶„ì„ ì„¤ì •
    MIN_CONFIDENCE_THRESHOLD = 0.6
    KEYWORD_MIN_FREQUENCY = 3
    TREND_ANALYSIS_WINDOW = 7  # 7ì¼ ë‹¨ìœ„ íŠ¸ë Œë“œ
    
    # í†µê³„ ì„¤ì •
    TOP_KEYWORDS_LIMIT = 20
    SENTIMENT_CATEGORIES = ['positive', 'negative', 'neutral']
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
    PERFORMANCE_MONITORING_ENABLED = True
    MAX_PERFORMANCE_RECORDS = 100

# =============================================================================
# Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 - ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸
# =============================================================================

class Epic7SentimentManager:
    """Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 - ì„±ëŠ¥ ìµœì í™” ì™„ì„±ë³¸"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        ê°ì„± ë°ì´í„° ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            config: ì‚¬ìš©ì ì •ì˜ ì„¤ì • (ì„ íƒì‚¬í•­)
        """
        self.config = config or SentimentConfig()
        
        # v3.3 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if self.config.PERFORMANCE_MONITORING_ENABLED:
            self.performance_monitor = PerformanceMonitor(self.config.MAX_PERFORMANCE_RECORDS)
        else:
            self.performance_monitor = None
        
        # v3.3 ë²„í¼ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.buffer_manager = SentimentBufferManager(
            self.config.BUFFER_SIZE, 
            self.config.BUFFER_FLUSH_INTERVAL
        )
        if self.performance_monitor:
            self.buffer_manager.set_performance_monitor(self.performance_monitor)
        
        # v3.3 ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.cleanup_manager = SmartCleanupManager(
            self.config.CLEANUP_INTERVAL,
            self.config.FORCE_CLEANUP_COUNT
        )
        if self.performance_monitor:
            self.cleanup_manager.set_performance_monitor(self.performance_monitor)
        
        # ìˆœí™˜ ì„í¬íŠ¸ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° ì„í¬íŠ¸
        try:
            from classifier import Epic7Classifier
            self.classifier = Epic7Classifier()
        except ImportError as e:
            logger.warning(f"Classifier ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            self.classifier = None
        
        # ë°ì´í„° êµ¬ì¡° ì´ˆê¸°í™”
        self.sentiment_data = self.load_sentiment_data()
        self.sentiment_cache = self.load_sentiment_cache()
        self.sentiment_trends = self.load_sentiment_trends()
        self.sentiment_keywords = self.load_sentiment_keywords()
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ ì²´í¬ ë° ì •ë¦¬
        self._check_and_cleanup_keywords()
        
        # í†µê³„ ì´ˆê¸°í™”
        self.stats = {
            'total_posts': 0,
            'processed_posts': 0,
            'immediate_saves': 0,
            'batch_saves': 0,
            'buffer_saves': 0,  # v3.3 ì¶”ê°€
            'smart_cleanups': 0,  # v3.3 ì¶”ê°€
            'errors': 0,
            'start_time': datetime.now().isoformat()
        }
        
        logger.info(f"Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 ì´ˆê¸°í™” ì™„ë£Œ - ì„±ëŠ¥ ìµœì í™” ì ìš©")
    
    # =============================================================================
    # âœ¨ v3.3 í•µì‹¬ ìµœì í™”: í‚¤ì›Œë“œ ë©”ëª¨ë¦¬ ê´€ë¦¬
    # =============================================================================
    
    def _check_and_cleanup_keywords(self):
        """í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ ì²´í¬ ë° ì •ë¦¬"""
        try:
            keywords = self.sentiment_data.get('keywords', {})
            if len(keywords) > self.config.MAX_KEYWORDS_COUNT:
                logger.info(f"í‚¤ì›Œë“œ ê°œìˆ˜ ì´ˆê³¼ ({len(keywords)}ê°œ) - ì •ë¦¬ ì‹œì‘")
                self._cleanup_keywords()
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì •ë¦¬ ì²´í¬ ì‹¤íŒ¨: {e}")
    
    @measure_performance
    def _cleanup_keywords(self):
        """ì˜¤ë˜ëœ/ì‚¬ìš©ë¹ˆë„ ë‚®ì€ í‚¤ì›Œë“œ ì •ë¦¬"""
        try:
            keywords = self.sentiment_data.get('keywords', {})
            if len(keywords) <= self.config.KEYWORD_CLEANUP_THRESHOLD:
                return
            
            # ì‚¬ìš© ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_keywords = sorted(
                keywords.items(),
                key=lambda x: x[1].get('total_count', 0),
                reverse=True
            )
            
            # ìƒìœ„ í‚¤ì›Œë“œë§Œ ìœ ì§€
            keep_count = self.config.KEYWORD_CLEANUP_THRESHOLD
            self.sentiment_data['keywords'] = dict(sorted_keywords[:keep_count])
            
            removed_count = len(keywords) - keep_count
            logger.info(f"ğŸ§¹ í‚¤ì›Œë“œ ì •ë¦¬ ì™„ë£Œ: {removed_count}ê°œ ì œê±° ({len(keywords)} â†’ {keep_count})")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    @measure_performance
    def _update_keywords_with_limit(self, sentiment_result: Dict) -> None:
        """í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ (ê°œìˆ˜ ì œí•œ ì ìš©)"""
        try:
            title = sentiment_result.get('title', '')
            content = sentiment_result.get('content', '')
            
            keywords = self._extract_keywords_from_text(title + ' ' + content)
            
            if 'keywords' not in self.sentiment_data:
                self.sentiment_data['keywords'] = {}
            
            # í‚¤ì›Œë“œ ê°œìˆ˜ ì œí•œ ì²´í¬
            if len(self.sentiment_data['keywords']) > self.config.MAX_KEYWORDS_COUNT:
                if self.cleanup_manager.should_cleanup():
                    self.cleanup_manager.execute_cleanup(self._cleanup_keywords)
            
            sentiment = sentiment_result.get('sentiment', 'neutral')
            
            for keyword in keywords:
                if keyword not in self.sentiment_data['keywords']:
                    # ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€ ì‹œ ê³µê°„ í™•ì¸
                    if len(self.sentiment_data['keywords']) >= self.config.MAX_KEYWORDS_COUNT:
                        logger.warning(f"í‚¤ì›Œë“œ ìµœëŒ€ ê°œìˆ˜ ë„ë‹¬ ({self.config.MAX_KEYWORDS_COUNT}ê°œ) - ìƒˆ í‚¤ì›Œë“œ ë¬´ì‹œ")
                        break
                    
                    self.sentiment_data['keywords'][keyword] = {
                        'total_count': 0,
                        'sentiments': {'positive': 0, 'negative': 0, 'neutral': 0}
                    }
                
                self.sentiment_data['keywords'][keyword]['total_count'] += 1
                self.sentiment_data['keywords'][keyword]['sentiments'][sentiment] += 1
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    # =============================================================================
    # âœ¨ v3.3 í•µì‹¬ ìµœì í™”: ë²„í¼ë§ ì €ì¥ ì‹œìŠ¤í…œ
    # =============================================================================
    
    @measure_performance
    def save_sentiment_immediately_optimized(self, sentiment_result: Dict) -> bool:
        """
        âœ¨ v3.3 ìµœì í™”: ê°œë³„ ê²Œì‹œê¸€ ê°ì„± ë¶„ì„ ê²°ê³¼ ì¦‰ì‹œ ì €ì¥ (ë²„í¼ë§ ì ìš©)
        
        Args:
            sentiment_result: ê°ì„± ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # 1. ê¸°ë³¸ ê²€ì¦
            if not sentiment_result or not sentiment_result.get('url'):
                logger.warning("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ê°ì„± ë¶„ì„ ê²°ê³¼")
                return False
            
            # 2. íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            sentiment_result['processed_at'] = datetime.now().isoformat()
            sentiment_result['save_method'] = 'immediate_optimized'
            
            # 3. ë²„í¼ì— ì¶”ê°€ (íŒŒì¼ I/O ìµœì í™”)
            buffer_success = self.buffer_manager.add_to_buffer(sentiment_result)
            
            # 4. ë©”ëª¨ë¦¬ ë‚´ ë°ì´í„° ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•´)
            self.sentiment_data['posts'].append(sentiment_result)
            
            # 5. í†µê³„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
            self._update_statistics_immediately(sentiment_result)
            
            # 6. í‚¤ì›Œë“œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (ë©”ëª¨ë¦¬ ì œí•œ ì ìš©)
            self._update_keywords_with_limit(sentiment_result)
            
            # 7. ì¼ê°„ ë¦¬í¬íŠ¸ ë°ì´í„° ì¦‰ì‹œ ê°±ì‹ 
            self._update_daily_reports_immediately(sentiment_result)
            
            # 8. ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ (í•„ìš” ì‹œì—ë§Œ)
            if self.cleanup_manager.should_cleanup():
                self.cleanup_manager.execute_cleanup(self._cleanup_old_data_smart)
            
            if buffer_success:
                self.stats['buffer_saves'] += 1
                self.stats['processed_posts'] += 1
                
                post_title = sentiment_result.get('title', 'Unknown')[:50]
                sentiment = sentiment_result.get('sentiment', 'neutral')
                confidence = sentiment_result.get('confidence', 0.0)
                
                logger.debug(f"ğŸ’¾ ìµœì í™” ì €ì¥ ì„±ê³µ: {post_title}... (ê°ì„±: {sentiment}, ì‹ ë¢°ë„: {confidence:.2f})")
                
                # 9. ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
                self._update_cache_immediately(sentiment_result)
                
                return True
            else:
                logger.error("ğŸ’¥ ë²„í¼ ì €ì¥ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            self.stats['errors'] += 1
            if self.performance_monitor:
                self.performance_monitor.record_error()
            logger.error(f"ğŸ’¥ ìµœì í™” ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    @measure_performance
    def _cleanup_old_data_smart(self) -> int:
        """ìŠ¤ë§ˆíŠ¸ ë°ì´í„° ì •ë¦¬ (í•„ìš”í•  ë•Œë§Œ ì‹¤í–‰)"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.config.DATA_RETENTION_DAYS)
            cutoff_iso = cutoff_date.isoformat()
            
            # ë©”ëª¨ë¦¬ ë‚´ ê²Œì‹œê¸€ ì •ë¦¬
            original_count = len(self.sentiment_data.get('posts', []))
            if original_count == 0:
                return 0
            
            self.sentiment_data['posts'] = [
                post for post in self.sentiment_data.get('posts', [])
                if post.get('processed_at', '') > cutoff_iso
            ]
            
            cleaned_count = original_count - len(self.sentiment_data['posts'])
            
            # ì¼ê°„ ë¦¬í¬íŠ¸ ì •ë¦¬
            if 'daily_reports' in self.sentiment_data:
                cutoff_date_str = cutoff_date.strftime('%Y-%m-%d')
                old_dates = [
                    date for date in self.sentiment_data['daily_reports'].keys()
                    if date < cutoff_date_str
                ]
                
                for date in old_dates:
                    del self.sentiment_data['daily_reports'][date]
                
                cleaned_count += len(old_dates)
            
            if cleaned_count > 0:
                logger.info(f"ğŸ§¹ ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ í•­ëª© ì œê±°")
                self.stats['smart_cleanups'] += 1
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
            
            return cleaned_count
            
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0
    
    # =============================================================================
    # âœ¨ v3.3 ë²„í¼ ê´€ë¦¬ì êµ¬í˜„
    # =============================================================================
    
    class SentimentBufferManager(BufferedSaveManager):
        """ê°ì„± ë°ì´í„° ì „ìš© ë²„í¼ ê´€ë¦¬ì"""
        
        def __init__(self, buffer_size: int, flush_interval: int):
            super().__init__(buffer_size, flush_interval)
            self.sentiment_manager = None
        
        def set_sentiment_manager(self, manager):
            """ê°ì„± ê´€ë¦¬ì ì°¸ì¡° ì„¤ì •"""
            self.sentiment_manager = manager
        
        def _write_buffer_to_file(self, buffer_data: List[Dict]):
            """ë²„í¼ ë°ì´í„°ë¥¼ JSONL íŒŒì¼ì— ì¶”ê°€"""
            try:
                # JSONL í˜•ì‹ìœ¼ë¡œ ì¶”ê°€ ì €ì¥ (ì„±ëŠ¥ ìµœì í™”)
                buffer_file = getattr(self.sentiment_manager.config, 'SENTIMENT_BUFFER_FILE', 'sentiment_buffer.jsonl')
                
                with open(buffer_file, 'a', encoding='utf-8') as f:
                    for item in buffer_data:
                        f.write(json.dumps(item, ensure_ascii=False) + '\n')
                
                logger.debug(f"ğŸ“ ë²„í¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {len(buffer_data)}ê°œ í•­ëª©")
                
            except Exception as e:
                logger.error(f"ë²„í¼ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
                raise
    
    # ë²„í¼ ê´€ë¦¬ì ì°¸ì¡° ì„¤ì •
    def _setup_buffer_manager(self):
        """ë²„í¼ ê´€ë¦¬ì ì„¤ì •"""
        if hasattr(self, 'buffer_manager'):
            self.buffer_manager.set_sentiment_manager(self)
    
    # =============================================================================
    # ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ì™„ì „ ë³´ì¡´ + ì„±ëŠ¥ ìµœì í™”)
    # =============================================================================
    
    # save_sentiment_immediatelyëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
    def save_sentiment_immediately(self, sentiment_result: Dict) -> bool:
        """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
        return self.save_sentiment_immediately_optimized(sentiment_result)
    
    def _update_daily_reports_immediately(self, sentiment_result: Dict) -> None:
        """ì¼ê°„ ë¦¬í¬íŠ¸ ë°ì´í„° ì¦‰ì‹œ ê°±ì‹  (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        try:
            current_date = datetime.now().strftime('%Y-%m-%d')
            
            if 'daily_reports' not in self.sentiment_data:
                self.sentiment_data['daily_reports'] = {}
            
            if current_date not in self.sentiment_data['daily_reports']:
                self.sentiment_data['daily_reports'][current_date] = {
                    'total_posts': 0,
                    'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0},
                    'average_confidence': 0.0,
                    'top_keywords': {},
                    'site_distribution': {},
                    'hourly_distribution': {},
                    'trend_direction': 'neutral',
                    'confidence_sum': 0.0,
                    'last_updated': datetime.now().isoformat()
                }
            
            daily_report = self.sentiment_data['daily_reports'][current_date]
            daily_report['total_posts'] += 1
            
            sentiment = sentiment_result.get('sentiment', 'neutral')
            if sentiment in daily_report['sentiment_distribution']:
                daily_report['sentiment_distribution'][sentiment] += 1
            
            confidence = sentiment_result.get('confidence', 0.0)
            daily_report['confidence_sum'] += confidence
            daily_report['average_confidence'] = daily_report['confidence_sum'] / daily_report['total_posts']
            
            source = sentiment_result.get('source', 'unknown')
            if source in daily_report['site_distribution']:
                daily_report['site_distribution'][source] += 1
            else:
                daily_report['site_distribution'][source] = 1
            
            current_hour = datetime.now().strftime('%H')
            if current_hour in daily_report['hourly_distribution']:
                daily_report['hourly_distribution'][current_hour] += 1
            else:
                daily_report['hourly_distribution'][current_hour] = 1
            
            title = sentiment_result.get('title', '')
            keywords = self._extract_keywords_from_text(title)
            for keyword in keywords:
                if keyword in daily_report['top_keywords']:
                    daily_report['top_keywords'][keyword] += 1
                else:
                    daily_report['top_keywords'][keyword] = 1
            
            if len(daily_report['top_keywords']) > self.config.TOP_KEYWORDS_LIMIT:
                sorted_keywords = sorted(
                    daily_report['top_keywords'].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )[:self.config.TOP_KEYWORDS_LIMIT]
                daily_report['top_keywords'] = dict(sorted_keywords)
            
            pos_ratio = daily_report['sentiment_distribution']['positive'] / max(1, daily_report['total_posts'])
            neg_ratio = daily_report['sentiment_distribution']['negative'] / max(1, daily_report['total_posts'])
            
            if pos_ratio > neg_ratio + 0.1:
                daily_report['trend_direction'] = 'positive'
            elif neg_ratio > pos_ratio + 0.1:
                daily_report['trend_direction'] = 'negative'
            else:
                daily_report['trend_direction'] = 'neutral'
            
            daily_report['last_updated'] = datetime.now().isoformat()
            
        except Exception as e:
            logger.error(f"ì¼ê°„ ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_statistics_immediately(self, sentiment_result: Dict) -> None:
        """í†µê³„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        try:
            if 'statistics' not in self.sentiment_data:
                self.sentiment_data['statistics'] = {
                    'total_posts': 0,
                    'sentiment_counts': {'positive': 0, 'negative': 0, 'neutral': 0},
                    'average_confidence': 0.0,
                    'site_stats': {},
                    'last_updated': datetime.now().isoformat()
                }
            
            stats = self.sentiment_data['statistics']
            stats['total_posts'] += 1
            
            sentiment = sentiment_result.get('sentiment', 'neutral')
            if sentiment in stats['sentiment_counts']:
                stats['sentiment_counts'][sentiment] += 1
            
            source = sentiment_result.get('source', 'unknown')
            if source not in stats['site_stats']:
                stats['site_stats'][source] = {'count': 0, 'sentiments': {'positive': 0, 'negative': 0, 'neutral': 0}}
            
            stats['site_stats'][source]['count'] += 1
            stats['site_stats'][source]['sentiments'][sentiment] += 1
            
            stats['last_updated'] = datetime.now().isoformat()
            
        except Exception as e:
            logger.error(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _update_cache_immediately(self, sentiment_result: Dict) -> None:
        """ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        try:
            url = sentiment_result.get('url', '')
            if url:
                self.sentiment_cache[url] = {
                    'sentiment': sentiment_result.get('sentiment'),
                    'confidence': sentiment_result.get('confidence'),
                    'cached_at': datetime.now().isoformat(),
                    'save_method': 'immediate_optimized'
                }
                
                # ìºì‹œ í¬ê¸° ì œí•œ (v3.3 ì¶”ê°€)
                if len(self.sentiment_cache) > 1000:
                    # ì˜¤ë˜ëœ ìºì‹œ 50% ì œê±°
                    cache_items = list(self.sentiment_cache.items())
                    self.sentiment_cache = dict(cache_items[-500:])
                    logger.debug("ğŸ—‘ï¸ ìºì‹œ í¬ê¸° ì œí•œ ì ìš©: 500ê°œë¡œ ì¶•ì†Œ")
                
        except Exception as e:
            logger.error(f"ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    # =============================================================================
    # v3.3 ì„±ëŠ¥ ìƒíƒœ ë° ëª¨ë‹ˆí„°ë§
    # =============================================================================
    
    def get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        summary = {
            'version': '3.3',
            'optimization_features': [
                'Memory optimization (keyword limit)',
                'Buffered I/O system',
                'Smart cleanup manager',
                'Performance monitoring'
            ],
            'runtime_stats': self.stats
        }
        
        if self.performance_monitor:
            summary['performance_metrics'] = self.performance_monitor.get_summary()
        
        if hasattr(self, 'buffer_manager'):
            summary['buffer_status'] = self.buffer_manager.get_buffer_status()
        
        if hasattr(self, 'cleanup_manager'):
            summary['cleanup_status'] = self.cleanup_manager.get_status()
        
        return summary
    
    def force_flush_all(self) -> bool:
        """ëª¨ë“  ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ"""
        try:
            if hasattr(self, 'buffer_manager'):
                success = self.buffer_manager.flush_buffer(force=True)
                if success:
                    logger.info("ğŸš€ ëª¨ë“  ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ ì™„ë£Œ")
                return success
            return True
        except Exception as e:
            logger.error(f"ë²„í¼ ê°•ì œ í”ŒëŸ¬ì‹œ ì‹¤íŒ¨: {e}")
            return False
    
    # ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ëª¨ë‘ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
    def load_sentiment_data(self) -> Dict:
        """ê°ì„± ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        try:
            if os.path.exists(self.config.SENTIMENT_DATA_FILE):
                with open(self.config.SENTIMENT_DATA_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"ê°ì„± ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data.get('posts', []))}ê°œ ê²Œì‹œê¸€")
                    return data
            else:
                logger.info("ìƒˆë¡œìš´ ê°ì„± ë°ì´í„° íŒŒì¼ ìƒì„±")
                return {
                    'posts': [],
                    'statistics': {},
                    'daily_reports': {},
                    'keywords': {},
                    'created_at': datetime.now().isoformat(),
                    'last_updated': datetime.now().isoformat(),
                    'version': '3.3'
                }
        except Exception as e:
            logger.error(f"ê°ì„± ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {'posts': [], 'statistics': {}, 'daily_reports': {}, 'keywords': {}}
    
    # ë‚˜ë¨¸ì§€ ê¸°ì¡´ í•¨ìˆ˜ë“¤ë„ ëª¨ë‘ ë™ì¼í•˜ê²Œ ìœ ì§€...
    # (save_sentiment_data_file, load_sentiment_cache, process_post_sentiment ë“±)

# =============================================================================
# âœ¨ FIXED: í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥ í•¨ìˆ˜ë“¤ (ì™„ì „ ë³´ì¡´)
# =============================================================================

def save_sentiment_data_immediately(post_data: Dict) -> bool:
    """í¸ì˜ í•¨ìˆ˜: ê°œë³„ ê²Œì‹œê¸€ ì¦‰ì‹œ ì €ì¥ (v3.3 ìµœì í™” ì ìš©)"""
    try:
        manager = Epic7SentimentManager()
        
        if 'sentiment' not in post_data:
            sentiment_result = manager.process_post_sentiment(post_data)
            if not sentiment_result:
                return False
        else:
            sentiment_result = post_data
        
        # v3.3 ìµœì í™”ëœ ì €ì¥ ì‚¬ìš©
        return manager.save_sentiment_immediately_optimized(sentiment_result)
        
    except Exception as e:
        logger.error(f"í¸ì˜ í•¨ìˆ˜ ì¦‰ì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_sentiment_data(posts_or_post: Union[List[Dict], Dict], 
                       sentiment_summary: Optional[Dict] = None) -> bool:
    """í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜ - v3.3 ìµœì í™” ì ìš©"""
    try:
        if posts_or_post is None:
            logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return True
        
        manager = Epic7SentimentManager()
        
        if isinstance(posts_or_post, dict):
            posts = [posts_or_post]
        elif isinstance(posts_or_post, list):
            posts = posts_or_post
        else:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…: {type(posts_or_post)}")
            return False
        
        if not posts:
            return True
        
        success_count = 0
        for post in posts:
            try:
                if 'sentiment' not in post:
                    result = manager.process_post_sentiment(post)
                    if result:
                        post.update(result)
                
                # v3.3 ìµœì í™”ëœ ì €ì¥ ì‚¬ìš©
                if manager.save_sentiment_immediately_optimized(post):
                    success_count += 1
                    
            except Exception as e:
                logger.error(f"ê°œë³„ ê²Œì‹œê¸€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ë§ˆì§€ë§‰ì— ë²„í¼ í”ŒëŸ¬ì‹œ
        manager.force_flush_all()
        
        logger.info(f"âœ… v3.3 ìµœì í™” ì €ì¥ ì™„ë£Œ: {success_count}/{len(posts)}ê°œ")
        return success_count > 0
        
    except Exception as e:
        logger.error(f"âŒ v3.3 ìµœì í™” ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

# ê¸°íƒ€ í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ (get_today_sentiment_summary, get_sentiment_summary) ìœ ì§€

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - v3.3 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í¬í•¨"""
    try:
        logger.info("Epic7 ê°ì„± ë°ì´í„° ê´€ë¦¬ì v3.3 ì‹œì‘ - ì„±ëŠ¥ ìµœì í™” ì ìš©")
        
        # ê´€ë¦¬ì ì´ˆê¸°í™”
        manager = Epic7SentimentManager()
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        test_data = [
            {
                'title': f'í…ŒìŠ¤íŠ¸ ê²Œì‹œê¸€ {i}',
                'content': f'í…ŒìŠ¤íŠ¸ ë‚´ìš© {i}',
                'url': f'https://test.com/{i}',
                'source': 'test',
                'sentiment': 'positive' if i % 3 == 0 else 'negative' if i % 3 == 1 else 'neutral',
                'confidence': 0.8
            }
            for i in range(100)
        ]
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for data in test_data:
            manager.save_sentiment_immediately_optimized(data)
        
        # ìµœì¢… í”ŒëŸ¬ì‹œ
        manager.force_flush_all()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        perf_summary = manager.get_performance_summary()
        logger.info(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {total_time:.3f}ì´ˆ (100ê°œ í•­ëª©)")
        logger.info(f"ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½: {perf_summary}")
        
    except Exception as e:
        logger.error(f"ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()